"""
nnUNetTrainerHSI
é›†æˆSPGAã€DSRå’ŒSSCAåˆ›æ–°ç‚¹çš„nnU-Netè®­ç»ƒå™¨

åˆ›æ–°ç‚¹ï¼š
1. SPGA - Spectral Prototype-Guided Adaptive Attention (ç¼–ç å™¨)
2. DSR - Dynamic Spectral Routing (ç¼–ç å™¨)
3. SSCA - Spectral-Spatial Channel Attention with Doubly Smoothed Prior (è·³è·ƒè¿æ¥)
   - è¶…è½»é‡SE-Net (<1Kå‚æ•°/stage)
   - åŒé‡å¹³æ»‘å¯†åº¦ä¼°è®¡å…ˆéªŒï¼ˆç†è®ºåˆ›æ–°ï¼‰
   - å…ˆéªŒç”¨äºåˆå§‹åŒ–æƒé‡ï¼ˆé›¶è¿è¡Œæ—¶å¼€é”€ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
nnUNetv2_train 502 3d_fullres 0 -tr nnUNetTrainerHSI
"""

import torch
import torch.nn as nn
from typing import Union, List, Tuple
from torch import autocast

from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer


class nnUNetTrainerHSI(nnUNetTrainer):
    """
    nnUNetTrainerHSI with SPGA + DSR
    
    åœ¨æ ‡å‡†nnU-NetåŸºç¡€ä¸Šé›†æˆSPGAå’ŒDSRæ¨¡å—
    """
    
    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict,
                 device: torch.device = torch.device('cuda')):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        """
        # === é…ç½® - SPGA + DSR + SSCA + PHSP ===
        self.use_spga = True     # âœ“ å¯ç”¨SPGA-Lite (ç¼–ç å™¨)
        self.use_dsr = True      # âœ“ å¯ç”¨DSR-Lite (ç¼–ç å™¨, 4ä¸“å®¶ç‰ˆæœ¬)
        self.use_ssca = False     # âœ— ç¦ç”¨SSCA (è¶…è½»é‡é€šé“æ³¨æ„åŠ›)
        self.use_phsp = False    # âœ— ç¦ç”¨PHSP (åŸå‹é©±åŠ¨å±‚çº§å…‰è°±å…ˆéªŒ - ç¦ç”¨)
        self.use_bear = False    # âœ— ç¦ç”¨BEAR (æ˜¾å­˜ä¸è¶³)
        self.use_pbar = False    # âœ— ç¦ç”¨
        self.use_scr = False     # âœ— ç¦ç”¨
        
        self.spectral_dim = 60  # å…‰è°±ç»´åº¦ï¼ˆæ ¹æ®å®é™…æ•°æ®ï¼š60ä¸ªæ³¢æ®µï¼‰
        
        # SPGAè½»é‡çº§é…ç½®
        self.num_spga_prototypes = 4
        self.spga_downsample_attention = True
        self.spga_apply_to_stages = [2, 3, 4]
        
        # DSRè½»é‡çº§é…ç½® (4ä¸“å®¶ç‰ˆæœ¬)
        self.num_dsr_experts = 4  # 4ä¸ªä¸“å®¶ï¼šå…‰è°±ã€ç©ºé—´ã€ç»†ç²’åº¦ã€æ ‡å‡†3D
        self.dsr_lightweight_experts = True
        self.dsr_apply_to_stages = [1, 2, 3]
        
        # SSCAé…ç½® (æ–°å¢ - è·³è·ƒè¿æ¥)
        self.spectral_weights_path = '/data/CXY/g/szy/spectral_prior_weights/spectral_prior_weights_final.npy'
        self.ssca_reduction = 4  # å‹ç¼©ç‡ï¼š4=æ ‡å‡†, 8=æ›´è½»é‡
        self.ssca_dropout_rate = 0.15  # Dropoutç‡ï¼ˆå‡å°‘è¿‡æ‹Ÿåˆï¼Œç¨³å®šval lossï¼‰
        self.ssca_apply_to_stages = [0, 1, 2, 3, 4, 5, 6]  # åº”ç”¨åˆ°æ‰€æœ‰è·³è·ƒè¿æ¥
        
        # PHSPé…ç½® (æ–°å¢ - åŸå‹é©±åŠ¨çš„å±‚çº§å…‰è°±å…ˆéªŒ)
        self.phsp_smooth_alpha = 0.001  # å¹³æ»‘æ€§æŸå¤±æƒé‡
        self.phsp_smooth_order = 1  # å¹³æ»‘é˜¶æ•°ï¼š1=ä¸€é˜¶å·®åˆ†, 2=äºŒé˜¶å·®åˆ†
        self.phsp_use_consistency = False  # æ˜¯å¦ä½¿ç”¨è·¨stageä¸€è‡´æ€§æŸå¤±
        self.phsp_consistency_alpha = 0.0005  # ä¸€è‡´æ€§æŸå¤±æƒé‡
        
        # BEARé…ç½® (æ–°å¢ - è§£ç å™¨)
        self.bear_use_lite = False  # False=æ ‡å‡†ç‰ˆ(30-50Kå‚æ•°), True=è¶…è½»é‡ç‰ˆ(15-20Kå‚æ•°)
        self.bear_use_uncertainty = True  # æ˜¯å¦ä½¿ç”¨ä¸ç¡®å®šæ€§å¼•å¯¼ï¼ˆæ¥è‡ªSDARï¼‰
        self.bear_uncertainty_threshold = 0.5  # ä¸ç¡®å®šæ€§é˜ˆå€¼
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(plans, configuration, fold, dataset_json, device)
        
        print("="*80)
        print("nnUNetTrainerHSI - SPGA + DSR + SSCA")
        print("="*80)
        print(f"  SPGA: {'âœ“ Enabled' if self.use_spga else 'âœ— Disabled'} (Encoder)")
        print(f"    - Prototypes: {self.num_spga_prototypes}")
        print(f"    - Apply to stages: {self.spga_apply_to_stages}")
        print(f"  DSR:  {'âœ“ Enabled' if self.use_dsr else 'âœ— Disabled'} (Encoder)")
        print(f"    - Num experts: {self.num_dsr_experts} (Spectral, Spatial, Fine-grained, Standard-3D)")
        print(f"    - Apply to stages: {self.dsr_apply_to_stages}")
        print(f"  SSCA: {'âœ“ Enabled' if self.use_ssca else 'âœ— Disabled'} (Skip Connections)")
        print(f"    - Reduction: {self.ssca_reduction}")
        print(f"    - Doubly Smoothed Prior: Yes")
        print(f"  PHSP: {'âœ“ Enabled' if self.use_phsp else 'âœ— Disabled'} (Skip Connections - Prototype-Driven)")
        print(f"  Spectral dim: {self.spectral_dim}")
        print("="*80)
    
    @staticmethod
    def build_network_architecture(architecture_class_name: str,
                                   arch_init_kwargs: dict,
                                   arch_init_kwargs_req_import: Union[List[str], Tuple[str, ...]],
                                   num_input_channels: int,
                                   num_output_channels: int,
                                   enable_deep_supervision: bool = True) -> nn.Module:
        """
        æ„å»ºåŒ…å«SPGAå’ŒDSRçš„ç½‘ç»œ
        """
        from dynamic_network_architectures.architectures.unet import PlainConvEncoder, UNetDecoder
        from dynamic_network_architectures.building_blocks.spga_module import SPGAModuleEfficientLite
        from dynamic_network_architectures.building_blocks.dsr_module import DSRModuleEfficientLite4Experts
        from dynamic_network_architectures.building_blocks.dspa_module import DSPAModule, DSPAModuleLite
        
        # å¤„ç†éœ€è¦å¯¼å…¥çš„å‚æ•°
        import importlib
        for param_name in arch_init_kwargs_req_import:
            if param_name in arch_init_kwargs and isinstance(arch_init_kwargs[param_name], str):
                module_path, class_name = arch_init_kwargs[param_name].rsplit('.', 1)
                module = importlib.import_module(module_path)
                arch_init_kwargs[param_name] = getattr(module, class_name)
        
        # è·å–ç½‘ç»œå‚æ•°
        n_stages = arch_init_kwargs['n_stages']
        features_per_stage = arch_init_kwargs['features_per_stage']
        conv_op = arch_init_kwargs['conv_op']
        kernel_sizes = arch_init_kwargs['kernel_sizes']
        strides = arch_init_kwargs['strides']
        n_conv_per_stage = arch_init_kwargs['n_conv_per_stage']
        n_conv_per_stage_decoder = arch_init_kwargs.get('n_conv_per_stage_decoder', n_conv_per_stage[:-1])
        
        conv_bias = arch_init_kwargs.get('conv_bias', False)
        norm_op = arch_init_kwargs.get('norm_op', None)
        norm_op_kwargs = arch_init_kwargs.get('norm_op_kwargs', {})
        dropout_op = arch_init_kwargs.get('dropout_op', None)
        dropout_op_kwargs = arch_init_kwargs.get('dropout_op_kwargs', {})
        nonlin = arch_init_kwargs.get('nonlin', nn.ReLU)
        nonlin_kwargs = arch_init_kwargs.get('nonlin_kwargs', {'inplace': True})
        nonlin_first = arch_init_kwargs.get('nonlin_first', False)
        
        # HSIå‚æ•° - ä½¿ç”¨ç±»çº§åˆ«çš„é»˜è®¤é…ç½®
        spectral_dim = 60  # å…‰è°±ç»´åº¦
        use_spga = True    # âœ“ å¯ç”¨SPGA (ç¼–ç å™¨)
        use_dsr = True     # âœ“ å¯ç”¨DSR (ç¼–ç å™¨, 4ä¸“å®¶ç‰ˆæœ¬)
        use_ssca = False   # âœ— ç¦ç”¨SSCA (è¶…è½»é‡é€šé“æ³¨æ„åŠ›)
        use_phsp = False   # âœ— ç¦ç”¨PHSP (è·³è·ƒè¿æ¥ - åŸå‹é©±åŠ¨ï¼Œç¦ç”¨)
        use_bear = False   # âœ— ç¦ç”¨BEAR (æ˜¾å­˜ä¸è¶³)
        use_scr = False    # âœ— ç¦ç”¨SCR
        
        # SSCAé…ç½®
        spectral_weights_path = '/data/CXY/g/szy/spectral_prior_weights/spectral_prior_weights_final.npy'
        ssca_reduction = 4  # å‹ç¼©ç‡ï¼š4=æ ‡å‡†, 8=æ›´è½»é‡
        ssca_dropout_rate = 0.15  # Dropoutç‡ï¼ˆå‡å°‘è¿‡æ‹Ÿåˆï¼‰
        ssca_use_doubly_smoothing = True  # ä½¿ç”¨åŒé‡å¹³æ»‘
        
        # BEARé…ç½®
        bear_use_lite = False  # False=æ ‡å‡†ç‰ˆ(30-50Kå‚æ•°), True=è¶…è½»é‡ç‰ˆ(15-20Kå‚æ•°)
        bear_use_uncertainty = True  # æ˜¯å¦ä½¿ç”¨ä¸ç¡®å®šæ€§å¼•å¯¼
        bear_uncertainty_threshold = 0.5  # ä¸ç¡®å®šæ€§é˜ˆå€¼
        
        print("\n" + "="*80)
        print("Building HSI-UNet")
        print("="*80)
        # åˆ›å»ºEncoder
        print("\n[1/3] Building Encoder...")
        encoder = PlainConvEncoder(
            num_input_channels,
            n_stages,
            features_per_stage,
            conv_op,
            kernel_sizes,
            strides,
            n_conv_per_stage,
            conv_bias,
            norm_op,
            norm_op_kwargs,
            dropout_op,
            dropout_op_kwargs,
            nonlin,
            nonlin_kwargs,
            return_skips=True,
            nonlin_first=nonlin_first,
        )
        
        # SPGAå’ŒDSRçš„é…ç½®
        num_spga_prototypes = 4
        spga_downsample_attention = True
        spga_apply_to_stages = [2, 3, 4]
        
        num_dsr_experts = 4  # 4ä¸“å®¶ç‰ˆæœ¬
        dsr_lightweight_experts = True
        dsr_apply_to_stages = [1, 2, 3]
        
        # æ·»åŠ SPGAæ¨¡å—
        if use_spga:
            print("\n[2/3] Adding SPGA Modules...")
            spga_modules = nn.ModuleList()
            for i, channels in enumerate(features_per_stage):
                if i in spga_apply_to_stages:
                    spga = SPGAModuleEfficientLite(
                        channels, 
                        spectral_dim, 
                        num_prototypes=num_spga_prototypes,
                        downsample_attention=spga_downsample_attention
                    )
                else:
                    spga = nn.Identity()
                spga_modules.append(spga)
        else:
            spga_modules = nn.ModuleList([nn.Identity() for _ in range(n_stages)])
        
        # æ·»åŠ DSRæ¨¡å— - ä½¿ç”¨4ä¸“å®¶å¢å¼ºç‰ˆ
        if use_dsr:
            print("\n[3/4] Adding DSR Modules (4-Expert Version)...")
            dsr_modules = nn.ModuleList()
            for i, channels in enumerate(features_per_stage):
                if i in dsr_apply_to_stages:
                    dsr = DSRModuleEfficientLite4Experts(
                        channels,
                        spectral_dim,
                        lightweight_experts=dsr_lightweight_experts
                    )
                else:
                    dsr = nn.Identity()
                dsr_modules.append(dsr)
        else:
            dsr_modules = nn.ModuleList([nn.Identity() for _ in range(n_stages)])
        
        # æ·»åŠ SSCAæ¨¡å— (æ–°å¢ - åº”ç”¨åœ¨skip connections)
        if use_ssca:
            from dynamic_network_architectures.building_blocks.ssca_module import build_ssca_module
            print("\n[4/6] Adding SSCA Modules (Spectral-Spatial Channel Attention with Doubly Smoothed Prior)...")
            ssca_modules = nn.ModuleList()
            for i, channels in enumerate(features_per_stage):
                ssca = build_ssca_module(
                    channels=channels,
                    spectral_dim=spectral_dim,
                    spectral_prior_path=spectral_weights_path,
                    reduction=ssca_reduction,
                    use_doubly_smoothing=ssca_use_doubly_smoothing,
                    dropout_rate=ssca_dropout_rate
                )
                ssca_modules.append(ssca)
        else:
            ssca_modules = nn.ModuleList([nn.Identity() for _ in range(n_stages)])
        
        # æ·»åŠ PHSPæ¨¡å— (æ–°å¢ - åŸå‹é©±åŠ¨çš„å±‚çº§å…‰è°±å…ˆéªŒ)
        phsp_module = None
        if use_phsp:
            from dynamic_network_architectures.building_blocks.phsp_module import build_phsp_module
            from dynamic_network_architectures.building_blocks.phsp_loss import PHSPCompositeLoss
            print("\n[5/6] Adding PHSP Module (Prototype-Driven Hierarchical Spectral Prior)...")
            
            # PHSPé…ç½®
            phsp_smooth_alpha = 0.001
            phsp_smooth_order = 1
            phsp_use_consistency = False
            phsp_consistency_alpha = 0.0005
            
            # æ„å»ºPHSPæ¨¡å—
            phsp_module = build_phsp_module(
                channels_per_stage=features_per_stage,
                spectral_dim=spectral_dim,
                num_prototypes=num_spga_prototypes,
                spga_stages=spga_apply_to_stages
            )
            
            print(f"  PHSP initialized with:")
            print(f"    - Smooth alpha: {phsp_smooth_alpha}")
            print(f"    - Smooth order: {phsp_smooth_order}")
            print(f"    - Consistency: {phsp_use_consistency}")
        
        # åˆ›å»ºDecoder
        print("\n[5/5] Building Decoder...")
        decoder = UNetDecoder(
            encoder,
            num_output_channels,
            n_conv_per_stage_decoder,
            enable_deep_supervision,
            nonlin_first
        )
        
        # æ·»åŠ BEARæ¨¡å— (æ–°å¢ - åº”ç”¨åœ¨decoder stages)
        if use_bear:
            from dynamic_network_architectures.building_blocks.bear_module import build_bear_module
            print("\n[5/5] Adding BEAR Modules (Boundary-Enhanced Adaptive Refinement)...")
            bear_modules = nn.ModuleList()
            # BEARåº”ç”¨åœ¨decoderçš„æ¯ä¸ªstage
            # Decoder stagesçš„é€šé“æ•°æ˜¯features_per_stageçš„åå‘
            decoder_features = list(reversed(features_per_stage[:-1]))  # æ’é™¤bottleneck
            for i, channels in enumerate(decoder_features):
                bear = build_bear_module(
                    channels=channels,
                    use_lite=bear_use_lite,
                    use_uncertainty=bear_use_uncertainty,
                    uncertainty_threshold=bear_uncertainty_threshold
                )
                bear_modules.append(bear)
        else:
            bear_modules = nn.ModuleList([nn.Identity() for _ in range(n_stages - 1)])
        
        # ç»„è£…å®Œæ•´ç½‘ç»œ
        class HSIUNet(nn.Module):
            def __init__(self):
                super().__init__()
                self.encoder = encoder
                self.spga_modules = spga_modules
                self.dsr_modules = dsr_modules
                self.ssca_modules = ssca_modules
                self.phsp_module = phsp_module  # æ–°å¢ï¼šPHSPæ¨¡å—
                self.bear_modules = bear_modules
                self.decoder = decoder
                self.use_spga = use_spga
                self.use_dsr = use_dsr
                self.use_ssca = use_ssca
                self.use_phsp = use_phsp  # æ–°å¢ï¼šPHSPå¼€å…³
                self.use_bear = use_bear
                self.use_scr = use_scr
                self.deep_supervision = enable_deep_supervision
                
                # PHSPè¾…åŠ©å˜é‡ï¼ˆç”¨äºä¿å­˜å…‰è°±å…ˆéªŒï¼Œä¾›lossè®¡ç®—ï¼‰
                self.spectral_priors = None
            
            def forward(self, x):
                # === Encoderé˜¶æ®µ ===
                skips = []
                for i, stage in enumerate(self.encoder.stages):
                    x = stage(x)
                    if self.use_spga:
                        x = self.spga_modules[i](x)
                    if self.use_dsr:
                        x = self.dsr_modules[i](x)
                    skips.append(x)
                
                # === SSCAé˜¶æ®µï¼šå…‰è°±-ç©ºé—´é€šé“æ³¨æ„åŠ›ï¼ˆåŒé‡å¹³æ»‘å…ˆéªŒå¼•å¯¼ï¼‰===
                if self.use_ssca and not self.use_phsp:
                    refined_skips = []
                    for i, skip in enumerate(skips):
                        # SSCA: è¶…è½»é‡SE-Net + åŒé‡å¹³æ»‘å…ˆéªŒåˆå§‹åŒ–
                        refined_skip = self.ssca_modules[i](skip)
                        refined_skips.append(refined_skip)
                    skips = refined_skips
                
                # === PHSPé˜¶æ®µï¼šåŸå‹é©±åŠ¨çš„å±‚çº§å…‰è°±å…ˆéªŒå­¦ä¹  ===
                if self.use_phsp:
                    # PHSP: ä»SPGAåŸå‹æå–åŠ¨æ€å…‰è°±å…ˆéªŒï¼Œåº”ç”¨åˆ°è·³è·ƒè¿æ¥
                    refined_skips, spectral_priors = self.phsp_module(skips, self.spga_modules)
                    skips = refined_skips
                    # ä¿å­˜å…‰è°±å…ˆéªŒï¼ˆç”¨äºlossè®¡ç®—ï¼‰
                    self.spectral_priors = spectral_priors
                else:
                    self.spectral_priors = None
                
                # === Decoderé˜¶æ®µ ===
                # è‡ªå®šä¹‰decoder forwardä»¥é›†æˆBEAR
                if self.use_bear:
                    seg_outputs = self._decoder_with_bear(skips)
                else:
                    seg_outputs = self.decoder(skips)
                
                return seg_outputs
            
            def _decoder_with_bear(self, skips):
                """
                è‡ªå®šä¹‰decoder forwardï¼Œåœ¨æ¯ä¸ªstageåº”ç”¨BEAR
                """
                # è·å–decoderçš„stages
                lres_input = skips[-1]
                seg_outputs = []
                
                # Decoderé€stageå¤„ç†
                for s in range(len(self.decoder.stages)):
                    # ä¸Šé‡‡æ ·å¹¶ä¸skip connectionèåˆ
                    x = self.decoder.transpconvs[s](lres_input)
                    x = torch.cat((x, skips[-(s+2)]), 1)
                    x = self.decoder.stages[s](x)
                    
                    # åº”ç”¨BEARï¼ˆè¾¹ç•Œå¢å¼ºï¼‰
                    if s < len(self.bear_modules) and not isinstance(self.bear_modules[s], nn.Identity):
                        # è·å–å¯¹åº”çš„ä¸ç¡®å®šæ€§å›¾ï¼ˆå¦‚æœæœ‰ï¼‰
                        uncertainty = None
                        if self.use_sdar and hasattr(self, 'uncertainty_maps') and len(self.uncertainty_maps) > 0:
                            # ä½¿ç”¨å¯¹åº”stageçš„ä¸ç¡®å®šæ€§å›¾
                            idx = -(s+2)  # å¯¹åº”skipçš„ç´¢å¼•
                            if idx >= -len(self.uncertainty_maps):
                                unc_info = self.uncertainty_maps[idx]
                                if unc_info is not None and 'uncertainty' in unc_info:
                                    uncertainty = unc_info['uncertainty']
                        
                        # åº”ç”¨BEAR
                        x, bear_info = self.bear_modules[s](x, uncertainty)
                        
                        # ä¿å­˜è¾¹ç•Œä¿¡æ¯ï¼ˆéªŒè¯/æ¨ç†æ—¶ï¼‰
                        if not self.training and bear_info is not None and 'boundary_map' in bear_info:
                            self.boundary_maps.append(bear_info['boundary_map'])
                    
                    # Deep supervisionè¾“å‡ºï¼ˆä¸æ ‡å‡†decoderä¸€è‡´ï¼‰
                    if self.deep_supervision:
                        seg_outputs.append(self.decoder.seg_layers[s](x))
                    elif s == (len(self.decoder.stages) - 1):
                        seg_outputs.append(self.decoder.seg_layers[-1](x))
                    
                    lres_input = x
                
                # åè½¬è¾“å‡ºåˆ—è¡¨ï¼ˆä»é«˜åˆ†è¾¨ç‡åˆ°ä½åˆ†è¾¨ç‡ï¼‰
                seg_outputs = seg_outputs[::-1]
                
                return seg_outputs
            
            def compute_conv_feature_map_size(self, input_size):
                return (self.encoder.compute_conv_feature_map_size(input_size) +
                       self.decoder.compute_conv_feature_map_size(input_size))
        
        network = HSIUNet()
        
        print("\n" + "="*80)
        print("âœ… Network Built Successfully!")
        print("="*80 + "\n")
        
        return network


# ================================================================================
# å˜ä½“Trainerï¼šé’ˆå¯¹val_lossæ³¢åŠ¨ä¼˜åŒ–
# ================================================================================

class nnUNetTrainerHSI_StableLR(nnUNetTrainerHSI):
    """
    ç¨³å®šå­¦ä¹ ç‡ç‰ˆæœ¬ - è§£å†³val_lossæ³¢åŠ¨é—®é¢˜
    
    æ”¹è¿›ï¼š
    1. é™ä½åˆå§‹å­¦ä¹ ç‡ï¼š0.0001 (åŸ0.0003)
    2. SSCAå·²å†…ç½®Dropout=0.15ï¼ˆå‡å°‘è¿‡æ‹Ÿåˆï¼‰
    3. æ›´å¹³æ»‘çš„å­¦ä¹ ç‡è°ƒåº¦
    
    é€‚ç”¨åœºæ™¯ï¼š
    - val_lossæ³¢åŠ¨å¤§
    - éªŒè¯é›†è¾ƒå°
    - éœ€è¦æ›´ç¨³å®šçš„æ”¶æ•›
    """
    
    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict,
                 device: torch.device = torch.device('cuda')):
        super().__init__(plans, configuration, fold, dataset_json, device)
        
        # é™ä½åˆå§‹å­¦ä¹ ç‡ï¼ˆæ›´ç¨³å®šï¼‰
        self.initial_lr = 3e-4  # ä»3e-4é™åˆ°1e-4
        
        # å¢åŠ SSCA dropoutï¼ˆè¿›ä¸€æ­¥ç¨³å®šï¼‰
        self.ssca_dropout_rate = 0.2  # ä»0.15å¢åŠ åˆ°0.2
        
        print("\n" + "="*80)
        print("ğŸ”§ nnUNetTrainerHSI_StableLR Configuration")
        print("="*80)
        print(f"Initial LR: {self.initial_lr} (â†“ from 3e-4)")
        print(f"SSCA Dropout: {self.ssca_dropout_rate} (â†‘ from 0.15)")
        print("Purpose: Reduce val_loss oscillation")
        print("="*80 + "\n")
