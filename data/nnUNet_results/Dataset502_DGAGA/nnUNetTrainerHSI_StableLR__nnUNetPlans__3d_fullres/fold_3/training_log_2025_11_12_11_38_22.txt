
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-11-12 11:38:22.781727: Using torch.compile... 
2025-11-12 11:38:24.275974: do_dummy_2d_data_aug: False 
2025-11-12 11:38:24.277966: Using splits from existing split file: /data/CXY/g/szy/data/nnUNet_preprocessed/Dataset502_DGAGA/splits_final.json 
2025-11-12 11:38:24.278219: The split file contains 5 splits. 
2025-11-12 11:38:24.278289: Desired fold for training: 3 
2025-11-12 11:38:24.278342: This split has 63 training and 16 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [256, 256, 32], 'median_image_size_in_voxels': [1280.0, 1024.0, 60.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': <class 'torch.nn.modules.conv.Conv3d'>, 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1], [2, 2, 1], [2, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>, 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': <class 'torch.nn.modules.activation.LeakyReLU'>, 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset502_DGAGA', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [1280, 1024, 60], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1.0, 'mean': 0.515815258026123, 'median': 0.5421549081802368, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 1.0, 'std': 0.29032525420188904}}} 
 
2025-11-12 11:38:33.401221: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-11-12 11:38:33.420797:  
2025-11-12 11:38:33.421322: Epoch 0 
2025-11-12 11:38:33.421602: Current learning rate: 0.0003 
2025-11-12 11:42:57.126800: train_loss 0.2087 
2025-11-12 11:42:57.127315: val_loss 0.1255 
2025-11-12 11:42:57.127421: Pseudo dice [0.5081] 
2025-11-12 11:42:57.127552: Epoch time: 263.71 s 
2025-11-12 11:42:57.127644: Yayy! New best EMA pseudo Dice: 0.5081 
2025-11-12 11:42:59.860004:  
2025-11-12 11:42:59.860371: Epoch 1 
2025-11-12 11:42:59.860503: Current learning rate: 0.0003 
2025-11-12 11:45:09.956989: train_loss 0.0655 
2025-11-12 11:45:09.957967: val_loss 0.0526 
2025-11-12 11:45:09.958169: Pseudo dice [0.5893] 
2025-11-12 11:45:09.958326: Epoch time: 130.1 s 
2025-11-12 11:45:09.958417: Yayy! New best EMA pseudo Dice: 0.5163 
2025-11-12 11:45:13.588870:  
2025-11-12 11:45:13.589362: Epoch 2 
2025-11-12 11:45:13.589528: Current learning rate: 0.00029 
2025-11-12 11:47:26.799531: train_loss 0.0064 
2025-11-12 11:47:26.800493: val_loss -0.0418 
2025-11-12 11:47:26.800670: Pseudo dice [0.644] 
2025-11-12 11:47:26.800837: Epoch time: 133.21 s 
2025-11-12 11:47:26.800929: Yayy! New best EMA pseudo Dice: 0.529 
2025-11-12 11:47:30.431746:  
2025-11-12 11:47:30.432107: Epoch 3 
2025-11-12 11:47:30.432283: Current learning rate: 0.00029 
2025-11-12 11:49:38.451454: train_loss -0.0048 
2025-11-12 11:49:38.452008: val_loss 0.0129 
2025-11-12 11:49:38.452220: Pseudo dice [0.6193] 
2025-11-12 11:49:38.452461: Epoch time: 128.02 s 
2025-11-12 11:49:38.452739: Yayy! New best EMA pseudo Dice: 0.5381 
2025-11-12 11:49:42.524757:  
2025-11-12 11:49:42.525109: Epoch 4 
2025-11-12 11:49:42.525251: Current learning rate: 0.00029 
2025-11-12 11:51:50.717631: train_loss -0.065 
2025-11-12 11:51:50.718129: val_loss -0.0983 
2025-11-12 11:51:50.718247: Pseudo dice [0.6818] 
2025-11-12 11:51:50.718372: Epoch time: 128.2 s 
2025-11-12 11:51:50.718469: Yayy! New best EMA pseudo Dice: 0.5524 
2025-11-12 11:51:55.064718:  
2025-11-12 11:51:55.065118: Epoch 5 
2025-11-12 11:51:55.065303: Current learning rate: 0.00029 
2025-11-12 11:54:02.738851: train_loss -0.1251 
2025-11-12 11:54:02.739181: val_loss 0.0585 
2025-11-12 11:54:02.739286: Pseudo dice [0.5845] 
2025-11-12 11:54:02.739402: Epoch time: 127.68 s 
2025-11-12 11:54:02.739491: Yayy! New best EMA pseudo Dice: 0.5556 
2025-11-12 11:54:06.346501:  
2025-11-12 11:54:06.346867: Epoch 6 
2025-11-12 11:54:06.347064: Current learning rate: 0.00028 
2025-11-12 11:56:10.636536: train_loss -0.101 
2025-11-12 11:56:10.636923: val_loss -0.0519 
2025-11-12 11:56:10.637051: Pseudo dice [0.6224] 
2025-11-12 11:56:10.637176: Epoch time: 124.29 s 
2025-11-12 11:56:10.637262: Yayy! New best EMA pseudo Dice: 0.5623 
2025-11-12 11:56:14.577142:  
2025-11-12 11:56:14.577527: Epoch 7 
2025-11-12 11:56:14.577678: Current learning rate: 0.00028 
2025-11-12 11:58:18.477805: train_loss -0.1566 
2025-11-12 11:58:18.479104: val_loss -0.0898 
2025-11-12 11:58:18.479883: Pseudo dice [0.6456] 
2025-11-12 11:58:18.480655: Epoch time: 123.9 s 
2025-11-12 11:58:18.481423: Yayy! New best EMA pseudo Dice: 0.5707 
2025-11-12 11:58:22.755062:  
2025-11-12 11:58:22.755384: Epoch 8 
2025-11-12 11:58:22.755574: Current learning rate: 0.00028 
2025-11-12 12:00:41.370833: train_loss -0.1295 
2025-11-12 12:00:41.371168: val_loss -0.1187 
2025-11-12 12:00:41.371273: Pseudo dice [0.6925] 
2025-11-12 12:00:41.371396: Epoch time: 138.62 s 
2025-11-12 12:00:41.371484: Yayy! New best EMA pseudo Dice: 0.5828 
2025-11-12 12:00:45.165014:  
2025-11-12 12:00:45.165347: Epoch 9 
2025-11-12 12:00:45.165538: Current learning rate: 0.00028 
2025-11-12 12:02:54.028443: train_loss -0.1726 
2025-11-12 12:02:54.028759: val_loss -0.1426 
2025-11-12 12:02:54.028872: Pseudo dice [0.6813] 
2025-11-12 12:02:54.028994: Epoch time: 128.87 s 
2025-11-12 12:02:54.029100: Yayy! New best EMA pseudo Dice: 0.5927 
2025-11-12 12:02:57.928188:  
2025-11-12 12:02:57.928586: Epoch 10 
2025-11-12 12:02:57.928790: Current learning rate: 0.00027 
2025-11-12 12:05:03.300863: train_loss -0.1685 
2025-11-12 12:05:03.301226: val_loss -0.1163 
2025-11-12 12:05:03.301419: Pseudo dice [0.6745] 
2025-11-12 12:05:03.301555: Epoch time: 125.38 s 
2025-11-12 12:05:03.301666: Yayy! New best EMA pseudo Dice: 0.6009 
2025-11-12 12:05:07.644830:  
2025-11-12 12:05:07.645233: Epoch 11 
2025-11-12 12:05:07.645414: Current learning rate: 0.00027 
2025-11-12 12:07:17.028761: train_loss -0.184 
2025-11-12 12:07:17.029105: val_loss -0.1061 
2025-11-12 12:07:17.029208: Pseudo dice [0.6719] 
2025-11-12 12:07:17.029331: Epoch time: 129.39 s 
2025-11-12 12:07:17.029426: Yayy! New best EMA pseudo Dice: 0.608 
2025-11-12 12:07:20.739549:  
2025-11-12 12:07:20.739934: Epoch 12 
2025-11-12 12:07:20.740145: Current learning rate: 0.00027 
2025-11-12 12:09:29.145201: train_loss -0.2061 
2025-11-12 12:09:29.145684: val_loss -0.0804 
2025-11-12 12:09:29.145857: Pseudo dice [0.6871] 
2025-11-12 12:09:29.145993: Epoch time: 128.41 s 
2025-11-12 12:09:29.146089: Yayy! New best EMA pseudo Dice: 0.6159 
2025-11-12 12:09:32.796357:  
2025-11-12 12:09:32.796729: Epoch 13 
2025-11-12 12:09:32.796939: Current learning rate: 0.00026 
2025-11-12 12:11:42.548216: train_loss -0.2113 
2025-11-12 12:11:42.548685: val_loss -0.1365 
2025-11-12 12:11:42.548789: Pseudo dice [0.7062] 
2025-11-12 12:11:42.548911: Epoch time: 129.76 s 
2025-11-12 12:11:42.549008: Yayy! New best EMA pseudo Dice: 0.6249 
2025-11-12 12:11:46.480133:  
2025-11-12 12:11:46.480740: Epoch 14 
2025-11-12 12:11:46.481135: Current learning rate: 0.00026 
2025-11-12 12:14:00.569030: train_loss -0.2217 
2025-11-12 12:14:00.569575: val_loss 0.0235 
2025-11-12 12:14:00.569698: Pseudo dice [0.5855] 
2025-11-12 12:14:00.569834: Epoch time: 134.09 s 
2025-11-12 12:14:02.005634:  
2025-11-12 12:14:02.006048: Epoch 15 
2025-11-12 12:14:02.006243: Current learning rate: 0.00026 
2025-11-12 12:16:07.536790: train_loss -0.2298 
2025-11-12 12:16:07.537106: val_loss -0.0754 
2025-11-12 12:16:07.537205: Pseudo dice [0.6663] 
2025-11-12 12:16:07.537323: Epoch time: 125.53 s 
2025-11-12 12:16:07.537416: Yayy! New best EMA pseudo Dice: 0.6255 
2025-11-12 12:16:11.250485:  
2025-11-12 12:16:11.250790: Epoch 16 
2025-11-12 12:16:11.251002: Current learning rate: 0.00026 
2025-11-12 12:18:16.428234: train_loss -0.2387 
2025-11-12 12:18:16.428630: val_loss 0.0268 
2025-11-12 12:18:16.428749: Pseudo dice [0.633] 
2025-11-12 12:18:16.428898: Epoch time: 125.18 s 
2025-11-12 12:18:16.428993: Yayy! New best EMA pseudo Dice: 0.6263 
2025-11-12 12:18:20.498196:  
2025-11-12 12:18:20.498529: Epoch 17 
2025-11-12 12:18:20.498687: Current learning rate: 0.00025 
2025-11-12 12:20:25.288051: train_loss -0.2287 
2025-11-12 12:20:25.288583: val_loss -0.0875 
2025-11-12 12:20:25.288732: Pseudo dice [0.6525] 
2025-11-12 12:20:25.288850: Epoch time: 124.79 s 
2025-11-12 12:20:25.288935: Yayy! New best EMA pseudo Dice: 0.6289 
2025-11-12 12:20:29.040746:  
2025-11-12 12:20:29.041044: Epoch 18 
2025-11-12 12:20:29.041309: Current learning rate: 0.00025 
2025-11-12 12:22:34.996686: train_loss -0.2663 
2025-11-12 12:22:34.997052: val_loss -0.0837 
2025-11-12 12:22:34.997224: Pseudo dice [0.6659] 
2025-11-12 12:22:34.997344: Epoch time: 125.96 s 
2025-11-12 12:22:34.997436: Yayy! New best EMA pseudo Dice: 0.6326 
2025-11-12 12:22:39.120324:  
2025-11-12 12:22:39.120696: Epoch 19 
2025-11-12 12:22:39.120894: Current learning rate: 0.00025 
2025-11-12 12:24:50.854464: train_loss -0.2455 
2025-11-12 12:24:50.854847: val_loss -0.1741 
2025-11-12 12:24:50.855030: Pseudo dice [0.7] 
2025-11-12 12:24:50.855149: Epoch time: 131.74 s 
2025-11-12 12:24:50.855238: Yayy! New best EMA pseudo Dice: 0.6393 
2025-11-12 12:24:54.439220:  
2025-11-12 12:24:54.439493: Epoch 20 
2025-11-12 12:24:54.439695: Current learning rate: 0.00025 
2025-11-12 12:27:06.292156: train_loss -0.2861 
2025-11-12 12:27:06.293511: val_loss 0.0476 
2025-11-12 12:27:06.294207: Pseudo dice [0.6045] 
2025-11-12 12:27:06.294907: Epoch time: 131.85 s 
2025-11-12 12:27:08.028992:  
2025-11-12 12:27:08.029443: Epoch 21 
2025-11-12 12:27:08.029587: Current learning rate: 0.00024 
2025-11-12 12:29:17.629673: train_loss -0.2269 
2025-11-12 12:29:17.630028: val_loss -0.0482 
2025-11-12 12:29:17.630147: Pseudo dice [0.6504] 
2025-11-12 12:29:17.630270: Epoch time: 129.6 s 
2025-11-12 12:29:19.032585:  
2025-11-12 12:29:19.032925: Epoch 22 
2025-11-12 12:29:19.033120: Current learning rate: 0.00024 
2025-11-12 12:31:33.479541: train_loss -0.2499 
2025-11-12 12:31:33.479935: val_loss -0.1309 
2025-11-12 12:31:33.480062: Pseudo dice [0.6842] 
2025-11-12 12:31:33.480178: Epoch time: 134.45 s 
2025-11-12 12:31:33.480264: Yayy! New best EMA pseudo Dice: 0.642 
2025-11-12 12:31:37.007406:  
2025-11-12 12:31:37.007853: Epoch 23 
2025-11-12 12:31:37.008003: Current learning rate: 0.00024 
2025-11-12 12:33:50.816467: train_loss -0.2454 
2025-11-12 12:33:50.816862: val_loss -0.0262 
2025-11-12 12:33:50.816961: Pseudo dice [0.6602] 
2025-11-12 12:33:50.817088: Epoch time: 133.81 s 
2025-11-12 12:33:50.817188: Yayy! New best EMA pseudo Dice: 0.6438 
2025-11-12 12:33:54.645482:  
2025-11-12 12:33:54.645849: Epoch 24 
2025-11-12 12:33:54.646065: Current learning rate: 0.00023 
2025-11-12 12:36:03.893173: train_loss -0.3187 
2025-11-12 12:36:03.893447: val_loss -0.1783 
2025-11-12 12:36:03.893675: Pseudo dice [0.7197] 
2025-11-12 12:36:03.893790: Epoch time: 129.25 s 
2025-11-12 12:36:03.893876: Yayy! New best EMA pseudo Dice: 0.6514 
2025-11-12 12:36:07.167111:  
2025-11-12 12:36:07.167421: Epoch 25 
2025-11-12 12:36:07.167621: Current learning rate: 0.00023 
2025-11-12 12:38:21.228750: train_loss -0.2918 
2025-11-12 12:38:21.229245: val_loss -0.0783 
2025-11-12 12:38:21.229391: Pseudo dice [0.6499] 
2025-11-12 12:38:21.229522: Epoch time: 134.06 s 
2025-11-12 12:38:22.615222:  
2025-11-12 12:38:22.615657: Epoch 26 
2025-11-12 12:38:22.615857: Current learning rate: 0.00023 
2025-11-12 12:40:32.007040: train_loss -0.2758 
2025-11-12 12:40:32.007578: val_loss -0.1776 
2025-11-12 12:40:32.007687: Pseudo dice [0.7357] 
2025-11-12 12:40:32.007807: Epoch time: 129.39 s 
2025-11-12 12:40:32.007900: Yayy! New best EMA pseudo Dice: 0.6597 
2025-11-12 12:40:35.576756:  
2025-11-12 12:40:35.577150: Epoch 27 
2025-11-12 12:40:35.577326: Current learning rate: 0.00023 
2025-11-12 12:42:48.941191: train_loss -0.2993 
2025-11-12 12:42:48.941443: val_loss -0.1741 
2025-11-12 12:42:48.941554: Pseudo dice [0.7067] 
2025-11-12 12:42:48.941663: Epoch time: 133.37 s 
2025-11-12 12:42:48.941759: Yayy! New best EMA pseudo Dice: 0.6644 
2025-11-12 12:42:52.520382:  
2025-11-12 12:42:52.520743: Epoch 28 
2025-11-12 12:42:52.520968: Current learning rate: 0.00022 
2025-11-12 12:45:02.087243: train_loss -0.325 
2025-11-12 12:45:02.087563: val_loss -0.0987 
2025-11-12 12:45:02.087665: Pseudo dice [0.6978] 
2025-11-12 12:45:02.087784: Epoch time: 129.57 s 
2025-11-12 12:45:02.087875: Yayy! New best EMA pseudo Dice: 0.6677 
2025-11-12 12:45:05.693395:  
2025-11-12 12:45:05.693781: Epoch 29 
2025-11-12 12:45:05.694021: Current learning rate: 0.00022 
2025-11-12 12:47:17.173614: train_loss -0.3134 
2025-11-12 12:47:17.174104: val_loss 0.0107 
2025-11-12 12:47:17.174239: Pseudo dice [0.6521] 
2025-11-12 12:47:17.174359: Epoch time: 131.48 s 
2025-11-12 12:47:18.576466:  
2025-11-12 12:47:18.576893: Epoch 30 
2025-11-12 12:47:18.577086: Current learning rate: 0.00022 
2025-11-12 12:49:29.168958: train_loss -0.3041 
2025-11-12 12:49:29.169307: val_loss -0.2266 
2025-11-12 12:49:29.169567: Pseudo dice [0.7553] 
2025-11-12 12:49:29.169705: Epoch time: 130.6 s 
2025-11-12 12:49:29.169808: Yayy! New best EMA pseudo Dice: 0.6751 
2025-11-12 12:49:32.644335:  
2025-11-12 12:49:32.644624: Epoch 31 
2025-11-12 12:49:32.644834: Current learning rate: 0.00021 
2025-11-12 12:51:44.886604: train_loss -0.3105 
2025-11-12 12:51:44.886948: val_loss -0.1163 
2025-11-12 12:51:44.887067: Pseudo dice [0.7] 
2025-11-12 12:51:44.887184: Epoch time: 132.24 s 
2025-11-12 12:51:44.887275: Yayy! New best EMA pseudo Dice: 0.6776 
2025-11-12 12:51:48.581939:  
2025-11-12 12:51:48.582333: Epoch 32 
2025-11-12 12:51:48.582540: Current learning rate: 0.00021 
2025-11-12 12:54:02.758173: train_loss -0.3184 
2025-11-12 12:54:02.758544: val_loss -0.0337 
2025-11-12 12:54:02.758660: Pseudo dice [0.6241] 
2025-11-12 12:54:02.758777: Epoch time: 134.18 s 
2025-11-12 12:54:04.148738:  
2025-11-12 12:54:04.149086: Epoch 33 
2025-11-12 12:54:04.149290: Current learning rate: 0.00021 
2025-11-12 12:56:13.758803: train_loss -0.3456 
2025-11-12 12:56:13.759197: val_loss -0.2126 
2025-11-12 12:56:13.759311: Pseudo dice [0.7468] 
2025-11-12 12:56:13.759428: Epoch time: 129.61 s 
2025-11-12 12:56:13.759605: Yayy! New best EMA pseudo Dice: 0.6797 
2025-11-12 12:56:18.013254:  
2025-11-12 12:56:18.013622: Epoch 34 
2025-11-12 12:56:18.013810: Current learning rate: 0.00021 
2025-11-12 12:58:32.221201: train_loss -0.3145 
2025-11-12 12:58:32.221521: val_loss -0.1551 
2025-11-12 12:58:32.221629: Pseudo dice [0.7124] 
2025-11-12 12:58:32.221857: Epoch time: 134.21 s 
2025-11-12 12:58:32.221952: Yayy! New best EMA pseudo Dice: 0.683 
2025-11-12 12:58:35.985900:  
2025-11-12 12:58:35.986308: Epoch 35 
2025-11-12 12:58:35.986476: Current learning rate: 0.0002 
2025-11-12 13:00:46.493588: train_loss -0.3156 
2025-11-12 13:00:46.494059: val_loss -0.145 
2025-11-12 13:00:46.494218: Pseudo dice [0.7118] 
2025-11-12 13:00:46.494333: Epoch time: 130.51 s 
2025-11-12 13:00:46.494421: Yayy! New best EMA pseudo Dice: 0.6859 
2025-11-12 13:00:50.207636:  
2025-11-12 13:00:50.208091: Epoch 36 
2025-11-12 13:00:50.208368: Current learning rate: 0.0002 
2025-11-12 13:02:59.535331: train_loss -0.3433 
2025-11-12 13:02:59.535707: val_loss -0.1672 
2025-11-12 13:02:59.535820: Pseudo dice [0.7202] 
2025-11-12 13:02:59.535942: Epoch time: 129.33 s 
2025-11-12 13:02:59.536038: Yayy! New best EMA pseudo Dice: 0.6893 
2025-11-12 13:03:03.404548:  
2025-11-12 13:03:03.404873: Epoch 37 
2025-11-12 13:03:03.405066: Current learning rate: 0.0002 
2025-11-12 13:05:14.914383: train_loss -0.3591 
2025-11-12 13:05:14.914853: val_loss -0.0312 
2025-11-12 13:05:14.914988: Pseudo dice [0.6313] 
2025-11-12 13:05:14.915106: Epoch time: 131.51 s 
2025-11-12 13:05:16.300194:  
2025-11-12 13:05:16.300604: Epoch 38 
2025-11-12 13:05:16.300751: Current learning rate: 0.0002 
2025-11-12 13:07:24.968523: train_loss -0.3416 
2025-11-12 13:07:24.968827: val_loss -0.1303 
2025-11-12 13:07:24.968954: Pseudo dice [0.7019] 
2025-11-12 13:07:24.969062: Epoch time: 128.67 s 
2025-11-12 13:07:26.361487:  
2025-11-12 13:07:26.361808: Epoch 39 
2025-11-12 13:07:26.362034: Current learning rate: 0.00019 
2025-11-12 13:09:35.976083: train_loss -0.355 
2025-11-12 13:09:35.976424: val_loss -0.2099 
2025-11-12 13:09:35.976524: Pseudo dice [0.7358] 
2025-11-12 13:09:35.976644: Epoch time: 129.62 s 
2025-11-12 13:09:35.976733: Yayy! New best EMA pseudo Dice: 0.6904 
2025-11-12 13:09:39.663782:  
2025-11-12 13:09:39.664205: Epoch 40 
2025-11-12 13:09:39.664392: Current learning rate: 0.00019 
2025-11-12 13:11:50.679128: train_loss -0.3643 
2025-11-12 13:11:50.679560: val_loss -0.1481 
2025-11-12 13:11:50.679680: Pseudo dice [0.7092] 
2025-11-12 13:11:50.679792: Epoch time: 131.02 s 
2025-11-12 13:11:50.679884: Yayy! New best EMA pseudo Dice: 0.6923 
2025-11-12 13:11:54.350090:  
2025-11-12 13:11:54.350464: Epoch 41 
2025-11-12 13:11:54.350615: Current learning rate: 0.00019 
2025-11-12 13:14:04.456684: train_loss -0.3695 
2025-11-12 13:14:04.457095: val_loss -0.11 
2025-11-12 13:14:04.457220: Pseudo dice [0.6792] 
2025-11-12 13:14:04.457420: Epoch time: 130.11 s 
2025-11-12 13:14:05.850580:  
2025-11-12 13:14:05.850927: Epoch 42 
2025-11-12 13:14:05.851118: Current learning rate: 0.00018 
2025-11-12 13:16:18.050045: train_loss -0.3811 
2025-11-12 13:16:18.050412: val_loss -0.0468 
2025-11-12 13:16:18.050514: Pseudo dice [0.6571] 
2025-11-12 13:16:18.050637: Epoch time: 132.2 s 
2025-11-12 13:16:19.437334:  
2025-11-12 13:16:19.437644: Epoch 43 
2025-11-12 13:16:19.437866: Current learning rate: 0.00018 
2025-11-12 13:18:28.808482: train_loss -0.3763 
2025-11-12 13:18:28.808891: val_loss -0.1168 
2025-11-12 13:18:28.809021: Pseudo dice [0.7055] 
2025-11-12 13:18:28.809143: Epoch time: 129.37 s 
2025-11-12 13:18:30.236493:  
2025-11-12 13:18:30.236894: Epoch 44 
2025-11-12 13:18:30.237047: Current learning rate: 0.00018 
2025-11-12 13:20:42.184855: train_loss -0.3522 
2025-11-12 13:20:42.185205: val_loss -0.1667 
2025-11-12 13:20:42.185309: Pseudo dice [0.7097] 
2025-11-12 13:20:42.185422: Epoch time: 131.95 s 
2025-11-12 13:20:44.111162:  
2025-11-12 13:20:44.111532: Epoch 45 
2025-11-12 13:20:44.111682: Current learning rate: 0.00018 
2025-11-12 13:22:56.110739: train_loss -0.3964 
2025-11-12 13:22:56.111130: val_loss -0.2051 
2025-11-12 13:22:56.111229: Pseudo dice [0.7375] 
2025-11-12 13:22:56.111345: Epoch time: 132.0 s 
2025-11-12 13:22:56.111437: Yayy! New best EMA pseudo Dice: 0.696 
2025-11-12 13:22:59.798729:  
2025-11-12 13:22:59.799106: Epoch 46 
2025-11-12 13:22:59.799264: Current learning rate: 0.00017 
2025-11-12 13:25:07.901087: train_loss -0.3911 
2025-11-12 13:25:07.901421: val_loss -0.1327 
2025-11-12 13:25:07.901539: Pseudo dice [0.6862] 
2025-11-12 13:25:07.901655: Epoch time: 128.11 s 
2025-11-12 13:25:09.272073:  
2025-11-12 13:25:09.272446: Epoch 47 
2025-11-12 13:25:09.272613: Current learning rate: 0.00017 
2025-11-12 13:27:17.701186: train_loss -0.3589 
2025-11-12 13:27:17.701520: val_loss -0.1506 
2025-11-12 13:27:17.701629: Pseudo dice [0.7055] 
2025-11-12 13:27:17.701746: Epoch time: 128.43 s 
2025-11-12 13:27:17.701938: Yayy! New best EMA pseudo Dice: 0.6961 
2025-11-12 13:27:21.390204:  
2025-11-12 13:27:21.390538: Epoch 48 
2025-11-12 13:27:21.390703: Current learning rate: 0.00017 
2025-11-12 13:29:29.117610: train_loss -0.3903 
2025-11-12 13:29:29.117925: val_loss -0.1676 
2025-11-12 13:29:29.118027: Pseudo dice [0.712] 
2025-11-12 13:29:29.118155: Epoch time: 127.73 s 
2025-11-12 13:29:29.118246: Yayy! New best EMA pseudo Dice: 0.6977 
2025-11-12 13:29:33.213760:  
2025-11-12 13:29:33.214322: Epoch 49 
2025-11-12 13:29:33.214490: Current learning rate: 0.00016 
2025-11-12 13:31:43.215151: train_loss -0.3718 
2025-11-12 13:31:43.215580: val_loss -0.1447 
2025-11-12 13:31:43.215680: Pseudo dice [0.6821] 
2025-11-12 13:31:43.215805: Epoch time: 130.0 s 
2025-11-12 13:31:45.139601:  
2025-11-12 13:31:45.139934: Epoch 50 
2025-11-12 13:31:45.140110: Current learning rate: 0.00016 
2025-11-12 13:34:05.503571: train_loss -0.4123 
2025-11-12 13:34:05.503910: val_loss -0.162 
2025-11-12 13:34:05.504017: Pseudo dice [0.6988] 
2025-11-12 13:34:05.504133: Epoch time: 140.37 s 
2025-11-12 13:34:06.872139:  
2025-11-12 13:34:06.872546: Epoch 51 
2025-11-12 13:34:06.872696: Current learning rate: 0.00016 
2025-11-12 13:37:19.511348: train_loss -0.4055 
2025-11-12 13:37:19.511811: val_loss -0.1313 
2025-11-12 13:37:19.511918: Pseudo dice [0.7081] 
2025-11-12 13:37:19.512028: Epoch time: 192.64 s 
2025-11-12 13:37:21.024747:  
2025-11-12 13:37:21.025007: Epoch 52 
2025-11-12 13:37:21.025146: Current learning rate: 0.00015 
2025-11-12 13:40:35.201049: train_loss -0.3912 
2025-11-12 13:40:35.201623: val_loss -0.2106 
2025-11-12 13:40:35.201804: Pseudo dice [0.7407] 
2025-11-12 13:40:35.201954: Epoch time: 194.18 s 
2025-11-12 13:40:35.202063: Yayy! New best EMA pseudo Dice: 0.7019 
2025-11-12 13:40:38.842110:  
2025-11-12 13:40:38.842431: Epoch 53 
2025-11-12 13:40:38.842571: Current learning rate: 0.00015 
2025-11-12 13:43:49.720903: train_loss -0.3912 
2025-11-12 13:43:49.721247: val_loss -0.2545 
2025-11-12 13:43:49.721389: Pseudo dice [0.7456] 
2025-11-12 13:43:49.721559: Epoch time: 190.88 s 
2025-11-12 13:43:49.721647: Yayy! New best EMA pseudo Dice: 0.7062 
2025-11-12 13:43:53.464025:  
2025-11-12 13:43:53.464339: Epoch 54 
2025-11-12 13:43:53.464480: Current learning rate: 0.00015 
2025-11-12 13:47:05.345484: train_loss -0.3593 
2025-11-12 13:47:05.345914: val_loss -0.0155 
2025-11-12 13:47:05.346028: Pseudo dice [0.6414] 
2025-11-12 13:47:05.346182: Epoch time: 191.88 s 
2025-11-12 13:47:06.826586:  
2025-11-12 13:47:06.826945: Epoch 55 
2025-11-12 13:47:06.827133: Current learning rate: 0.00015 
2025-11-12 13:50:18.449789: train_loss -0.408 
2025-11-12 13:50:18.450230: val_loss -0.2366 
2025-11-12 13:50:18.450354: Pseudo dice [0.7515] 
2025-11-12 13:50:18.450491: Epoch time: 191.63 s 
2025-11-12 13:50:19.871996:  
2025-11-12 13:50:19.872355: Epoch 56 
2025-11-12 13:50:19.872504: Current learning rate: 0.00014 
2025-11-12 13:53:35.139361: train_loss -0.3638 
2025-11-12 13:53:35.139938: val_loss -0.2288 
2025-11-12 13:53:35.140060: Pseudo dice [0.7269] 
2025-11-12 13:53:35.140202: Epoch time: 195.27 s 
2025-11-12 13:53:35.140304: Yayy! New best EMA pseudo Dice: 0.7071 
2025-11-12 13:53:39.032406:  
2025-11-12 13:53:39.032875: Epoch 57 
2025-11-12 13:53:39.033062: Current learning rate: 0.00014 
2025-11-12 13:56:54.660108: train_loss -0.4311 
2025-11-12 13:56:54.660459: val_loss -0.0927 
2025-11-12 13:56:54.660568: Pseudo dice [0.7094] 
2025-11-12 13:56:54.660693: Epoch time: 195.63 s 
2025-11-12 13:56:54.660818: Yayy! New best EMA pseudo Dice: 0.7073 
2025-11-12 13:56:58.318485:  
2025-11-12 13:56:58.318774: Epoch 58 
2025-11-12 13:56:58.318922: Current learning rate: 0.00014 
2025-11-12 14:00:05.872622: train_loss -0.3802 
2025-11-12 14:00:05.873039: val_loss -0.2527 
2025-11-12 14:00:05.873157: Pseudo dice [0.7498] 
2025-11-12 14:00:05.873273: Epoch time: 187.56 s 
2025-11-12 14:00:05.873363: Yayy! New best EMA pseudo Dice: 0.7116 
2025-11-12 14:00:09.442251:  
2025-11-12 14:00:09.442598: Epoch 59 
2025-11-12 14:00:09.442755: Current learning rate: 0.00013 
2025-11-12 14:02:18.016532: train_loss -0.3964 
2025-11-12 14:02:18.016978: val_loss -0.165 
2025-11-12 14:02:18.017082: Pseudo dice [0.7228] 
2025-11-12 14:02:18.017203: Epoch time: 128.58 s 
2025-11-12 14:02:18.017290: Yayy! New best EMA pseudo Dice: 0.7127 
2025-11-12 14:02:22.229772:  
2025-11-12 14:02:22.230200: Epoch 60 
2025-11-12 14:02:22.230408: Current learning rate: 0.00013 
2025-11-12 14:04:34.762793: train_loss -0.4189 
2025-11-12 14:04:34.763139: val_loss -0.2338 
2025-11-12 14:04:34.763247: Pseudo dice [0.723] 
2025-11-12 14:04:34.763387: Epoch time: 132.54 s 
2025-11-12 14:04:34.763479: Yayy! New best EMA pseudo Dice: 0.7137 
2025-11-12 14:04:38.474641:  
2025-11-12 14:04:38.475065: Epoch 61 
2025-11-12 14:04:38.475210: Current learning rate: 0.00013 
2025-11-12 14:06:49.098035: train_loss -0.4161 
2025-11-12 14:06:49.098465: val_loss -0.2756 
2025-11-12 14:06:49.098696: Pseudo dice [0.7331] 
2025-11-12 14:06:49.098842: Epoch time: 130.63 s 
2025-11-12 14:06:49.098954: Yayy! New best EMA pseudo Dice: 0.7157 
2025-11-12 14:06:52.761109:  
2025-11-12 14:06:52.761553: Epoch 62 
2025-11-12 14:06:52.761711: Current learning rate: 0.00013 
2025-11-12 14:09:25.459960: train_loss -0.4433 
2025-11-12 14:09:25.460263: val_loss -0.1192 
2025-11-12 14:09:25.460414: Pseudo dice [0.7033] 
2025-11-12 14:09:25.460533: Epoch time: 152.7 s 
2025-11-12 14:09:26.947531:  
2025-11-12 14:09:26.947892: Epoch 63 
2025-11-12 14:09:26.948082: Current learning rate: 0.00012 
2025-11-12 14:12:43.057085: train_loss -0.4243 
2025-11-12 14:12:43.057481: val_loss -0.2056 
2025-11-12 14:12:43.057666: Pseudo dice [0.7176] 
2025-11-12 14:12:43.057792: Epoch time: 196.11 s 
2025-11-12 14:12:44.655197:  
2025-11-12 14:12:44.655601: Epoch 64 
2025-11-12 14:12:44.655791: Current learning rate: 0.00012 
2025-11-12 14:16:00.767738: train_loss -0.4472 
2025-11-12 14:16:00.768142: val_loss -0.1819 
2025-11-12 14:16:00.768243: Pseudo dice [0.7302] 
2025-11-12 14:16:00.768362: Epoch time: 196.12 s 
2025-11-12 14:16:00.768451: Yayy! New best EMA pseudo Dice: 0.7163 
2025-11-12 14:16:04.443630:  
2025-11-12 14:16:04.443982: Epoch 65 
2025-11-12 14:16:04.444167: Current learning rate: 0.00012 
2025-11-12 14:18:58.664171: train_loss -0.4653 
2025-11-12 14:18:58.664601: val_loss -0.2138 
2025-11-12 14:18:58.664874: Pseudo dice [0.7393] 
2025-11-12 14:18:58.665051: Epoch time: 174.22 s 
2025-11-12 14:18:58.665178: Yayy! New best EMA pseudo Dice: 0.7186 
2025-11-12 14:19:02.151000:  
2025-11-12 14:19:02.151451: Epoch 66 
2025-11-12 14:19:02.151642: Current learning rate: 0.00011 
2025-11-12 14:21:13.641574: train_loss -0.4454 
2025-11-12 14:21:13.641940: val_loss -0.1497 
2025-11-12 14:21:13.642057: Pseudo dice [0.7079] 
2025-11-12 14:21:13.642240: Epoch time: 131.49 s 
2025-11-12 14:21:15.077633:  
2025-11-12 14:21:15.078011: Epoch 67 
2025-11-12 14:21:15.078206: Current learning rate: 0.00011 
2025-11-12 14:23:28.580957: train_loss -0.4604 
2025-11-12 14:23:28.581332: val_loss -0.2084 
2025-11-12 14:23:28.581451: Pseudo dice [0.7533] 
2025-11-12 14:23:28.581568: Epoch time: 133.51 s 
2025-11-12 14:23:28.581654: Yayy! New best EMA pseudo Dice: 0.7211 
2025-11-12 14:23:32.149715:  
2025-11-12 14:23:32.150115: Epoch 68 
2025-11-12 14:23:32.150305: Current learning rate: 0.00011 
2025-11-12 14:25:42.290615: train_loss -0.434 
2025-11-12 14:25:42.290968: val_loss -0.2327 
2025-11-12 14:25:42.291071: Pseudo dice [0.7301] 
2025-11-12 14:25:42.291187: Epoch time: 130.14 s 
2025-11-12 14:25:42.291286: Yayy! New best EMA pseudo Dice: 0.722 
2025-11-12 14:25:46.195001:  
2025-11-12 14:25:46.195386: Epoch 69 
2025-11-12 14:25:46.195581: Current learning rate: 0.0001 
2025-11-12 14:27:55.313380: train_loss -0.4858 
2025-11-12 14:27:55.313841: val_loss -0.2487 
2025-11-12 14:27:55.314003: Pseudo dice [0.7523] 
2025-11-12 14:27:55.314129: Epoch time: 129.12 s 
2025-11-12 14:27:55.314227: Yayy! New best EMA pseudo Dice: 0.725 
2025-11-12 14:27:59.104821:  
2025-11-12 14:27:59.105206: Epoch 70 
2025-11-12 14:27:59.105396: Current learning rate: 0.0001 
2025-11-12 14:30:12.044164: train_loss -0.4539 
2025-11-12 14:30:12.044638: val_loss -0.2 
2025-11-12 14:30:12.044839: Pseudo dice [0.7289] 
2025-11-12 14:30:12.044999: Epoch time: 132.94 s 
2025-11-12 14:30:12.045098: Yayy! New best EMA pseudo Dice: 0.7254 
2025-11-12 14:30:15.630230:  
2025-11-12 14:30:15.630685: Epoch 71 
2025-11-12 14:30:15.630913: Current learning rate: 0.0001 
2025-11-12 14:32:26.615080: train_loss -0.413 
2025-11-12 14:32:26.615567: val_loss -0.2786 
2025-11-12 14:32:26.615682: Pseudo dice [0.7476] 
2025-11-12 14:32:26.615810: Epoch time: 130.99 s 
2025-11-12 14:32:26.615915: Yayy! New best EMA pseudo Dice: 0.7276 
2025-11-12 14:32:30.158161:  
2025-11-12 14:32:30.158575: Epoch 72 
2025-11-12 14:32:30.158720: Current learning rate: 0.0001 
2025-11-12 14:34:37.870150: train_loss -0.4102 
2025-11-12 14:34:37.870665: val_loss -0.137 
2025-11-12 14:34:37.870773: Pseudo dice [0.714] 
2025-11-12 14:34:37.870893: Epoch time: 127.72 s 
2025-11-12 14:34:39.327968:  
2025-11-12 14:34:39.328303: Epoch 73 
2025-11-12 14:34:39.328504: Current learning rate: 9e-05 
2025-11-12 14:36:48.925826: train_loss -0.4424 
2025-11-12 14:36:48.926235: val_loss -0.338 
2025-11-12 14:36:48.926353: Pseudo dice [0.7671] 
2025-11-12 14:36:48.926470: Epoch time: 129.6 s 
2025-11-12 14:36:48.926683: Yayy! New best EMA pseudo Dice: 0.7304 
2025-11-12 14:36:52.440479:  
2025-11-12 14:36:52.440861: Epoch 74 
2025-11-12 14:36:52.441093: Current learning rate: 9e-05 
2025-11-12 14:39:03.003253: train_loss -0.4597 
2025-11-12 14:39:03.003764: val_loss 0.0227 
2025-11-12 14:39:03.003883: Pseudo dice [0.6734] 
2025-11-12 14:39:03.004029: Epoch time: 130.57 s 
2025-11-12 14:39:04.474746:  
2025-11-12 14:39:04.475189: Epoch 75 
2025-11-12 14:39:04.475348: Current learning rate: 9e-05 
2025-11-12 14:41:09.620218: train_loss -0.4382 
2025-11-12 14:41:09.620626: val_loss -0.2143 
2025-11-12 14:41:09.620777: Pseudo dice [0.7233] 
2025-11-12 14:41:09.620900: Epoch time: 125.15 s 
2025-11-12 14:41:11.078496:  
2025-11-12 14:41:11.078964: Epoch 76 
2025-11-12 14:41:11.079182: Current learning rate: 8e-05 
2025-11-12 14:43:21.921590: train_loss -0.4566 
2025-11-12 14:43:21.922001: val_loss -0.198 
2025-11-12 14:43:21.922139: Pseudo dice [0.7334] 
2025-11-12 14:43:21.922261: Epoch time: 130.85 s 
2025-11-12 14:43:23.389074:  
2025-11-12 14:43:23.389584: Epoch 77 
2025-11-12 14:43:23.389908: Current learning rate: 8e-05 
2025-11-12 14:45:28.717479: train_loss -0.4583 
2025-11-12 14:45:28.717884: val_loss -0.122 
2025-11-12 14:45:28.717993: Pseudo dice [0.7012] 
2025-11-12 14:45:28.718112: Epoch time: 125.33 s 
2025-11-12 14:45:30.300759:  
2025-11-12 14:45:30.301124: Epoch 78 
2025-11-12 14:45:30.301322: Current learning rate: 8e-05 
2025-11-12 14:47:39.247523: train_loss -0.4832 
2025-11-12 14:47:39.247907: val_loss -0.2542 
2025-11-12 14:47:39.248010: Pseudo dice [0.7547] 
2025-11-12 14:47:39.248126: Epoch time: 128.95 s 
2025-11-12 14:47:40.781274:  
2025-11-12 14:47:40.781648: Epoch 79 
2025-11-12 14:47:40.781842: Current learning rate: 7e-05 
2025-11-12 14:49:55.760011: train_loss -0.4887 
2025-11-12 14:49:55.760400: val_loss -0.2376 
2025-11-12 14:49:55.760501: Pseudo dice [0.7428] 
2025-11-12 14:49:55.760629: Epoch time: 134.98 s 
2025-11-12 14:49:57.224709:  
2025-11-12 14:49:57.225137: Epoch 80 
2025-11-12 14:49:57.225281: Current learning rate: 7e-05 
2025-11-12 14:52:10.039316: train_loss -0.5136 
2025-11-12 14:52:10.039732: val_loss -0.1179 
2025-11-12 14:52:10.039865: Pseudo dice [0.7185] 
2025-11-12 14:52:10.040108: Epoch time: 132.82 s 
2025-11-12 14:52:11.517920:  
2025-11-12 14:52:11.518330: Epoch 81 
2025-11-12 14:52:11.518521: Current learning rate: 7e-05 
2025-11-12 14:54:22.438774: train_loss -0.4755 
2025-11-12 14:54:22.439147: val_loss -0.3145 
2025-11-12 14:54:22.439265: Pseudo dice [0.7889] 
2025-11-12 14:54:22.439401: Epoch time: 130.92 s 
2025-11-12 14:54:22.439503: Yayy! New best EMA pseudo Dice: 0.7331 
2025-11-12 14:54:26.547542:  
2025-11-12 14:54:26.548003: Epoch 82 
2025-11-12 14:54:26.548181: Current learning rate: 6e-05 
2025-11-12 14:56:36.048639: train_loss -0.4707 
2025-11-12 14:56:36.049121: val_loss -0.2852 
2025-11-12 14:56:36.049395: Pseudo dice [0.7485] 
2025-11-12 14:56:36.049590: Epoch time: 129.5 s 
2025-11-12 14:56:36.049742: Yayy! New best EMA pseudo Dice: 0.7346 
2025-11-12 14:56:39.687355:  
2025-11-12 14:56:39.687781: Epoch 83 
2025-11-12 14:56:39.687972: Current learning rate: 6e-05 
2025-11-12 14:58:48.243010: train_loss -0.4445 
2025-11-12 14:58:48.243346: val_loss -0.302 
2025-11-12 14:58:48.243451: Pseudo dice [0.759] 
2025-11-12 14:58:48.243569: Epoch time: 128.56 s 
2025-11-12 14:58:48.243657: Yayy! New best EMA pseudo Dice: 0.7371 
2025-11-12 14:58:51.946766:  
2025-11-12 14:58:51.947101: Epoch 84 
2025-11-12 14:58:51.947433: Current learning rate: 6e-05 
2025-11-12 15:00:59.141237: train_loss -0.4793 
2025-11-12 15:00:59.141588: val_loss -0.2499 
2025-11-12 15:00:59.141691: Pseudo dice [0.7375] 
2025-11-12 15:00:59.141809: Epoch time: 127.2 s 
2025-11-12 15:00:59.141898: Yayy! New best EMA pseudo Dice: 0.7371 
2025-11-12 15:01:02.934703:  
2025-11-12 15:01:02.935093: Epoch 85 
2025-11-12 15:01:02.935303: Current learning rate: 5e-05 
2025-11-12 15:03:24.967846: train_loss -0.5118 
2025-11-12 15:03:24.968240: val_loss -0.3146 
2025-11-12 15:03:24.968345: Pseudo dice [0.7883] 
2025-11-12 15:03:24.968468: Epoch time: 142.04 s 
2025-11-12 15:03:24.968557: Yayy! New best EMA pseudo Dice: 0.7422 
2025-11-12 15:03:28.818299:  
2025-11-12 15:03:28.818758: Epoch 86 
2025-11-12 15:03:28.818946: Current learning rate: 5e-05 
2025-11-12 15:07:16.751508: train_loss -0.4697 
2025-11-12 15:07:16.751894: val_loss -0.2819 
2025-11-12 15:07:16.752046: Pseudo dice [0.753] 
2025-11-12 15:07:16.752215: Epoch time: 227.94 s 
2025-11-12 15:07:16.752348: Yayy! New best EMA pseudo Dice: 0.7433 
2025-11-12 15:07:20.383466:  
2025-11-12 15:07:20.383934: Epoch 87 
2025-11-12 15:07:20.384223: Current learning rate: 5e-05 
2025-11-12 15:11:06.899405: train_loss -0.5049 
2025-11-12 15:11:06.899806: val_loss -0.2637 
2025-11-12 15:11:06.899971: Pseudo dice [0.7505] 
2025-11-12 15:11:06.900086: Epoch time: 226.52 s 
2025-11-12 15:11:06.900182: Yayy! New best EMA pseudo Dice: 0.744 
2025-11-12 15:11:10.531364:  
2025-11-12 15:11:10.531692: Epoch 88 
2025-11-12 15:11:10.531952: Current learning rate: 4e-05 
2025-11-12 15:14:57.235160: train_loss -0.497 
2025-11-12 15:14:57.235485: val_loss -0.2205 
2025-11-12 15:14:57.235620: Pseudo dice [0.7326] 
2025-11-12 15:14:57.235738: Epoch time: 226.71 s 
2025-11-12 15:14:59.169227:  
2025-11-12 15:14:59.169541: Epoch 89 
2025-11-12 15:14:59.169740: Current learning rate: 4e-05 
2025-11-12 15:18:02.725237: train_loss -0.495 
2025-11-12 15:18:02.725562: val_loss -0.1219 
2025-11-12 15:18:02.725663: Pseudo dice [0.7027] 
2025-11-12 15:18:02.725782: Epoch time: 183.56 s 
2025-11-12 15:18:04.152021:  
2025-11-12 15:18:04.152390: Epoch 90 
2025-11-12 15:18:04.152596: Current learning rate: 4e-05 
2025-11-12 15:21:50.866680: train_loss -0.4909 
2025-11-12 15:21:50.867108: val_loss -0.1966 
2025-11-12 15:21:50.867213: Pseudo dice [0.7238] 
2025-11-12 15:21:50.867335: Epoch time: 226.72 s 
2025-11-12 15:21:52.335333:  
2025-11-12 15:21:52.335727: Epoch 91 
2025-11-12 15:21:52.335910: Current learning rate: 3e-05 
2025-11-12 15:25:39.892494: train_loss -0.5045 
2025-11-12 15:25:39.892838: val_loss -0.0935 
2025-11-12 15:25:39.892953: Pseudo dice [0.6938] 
2025-11-12 15:25:39.893075: Epoch time: 227.56 s 
2025-11-12 15:25:41.245237:  
2025-11-12 15:25:41.245641: Epoch 92 
2025-11-12 15:25:41.245818: Current learning rate: 3e-05 
2025-11-12 15:29:27.678118: train_loss -0.5151 
2025-11-12 15:29:27.678547: val_loss -0.2543 
2025-11-12 15:29:27.678741: Pseudo dice [0.747] 
2025-11-12 15:29:27.678862: Epoch time: 226.44 s 
2025-11-12 15:29:29.613894:  
2025-11-12 15:29:29.614285: Epoch 93 
2025-11-12 15:29:29.614503: Current learning rate: 3e-05 
2025-11-12 15:33:16.132864: train_loss -0.5348 
2025-11-12 15:33:16.133329: val_loss -0.1103 
2025-11-12 15:33:16.133547: Pseudo dice [0.6971] 
2025-11-12 15:33:16.133674: Epoch time: 226.52 s 
2025-11-12 15:33:17.599059:  
2025-11-12 15:33:17.599403: Epoch 94 
2025-11-12 15:33:17.599588: Current learning rate: 2e-05 
2025-11-12 15:37:03.585963: train_loss -0.4737 
2025-11-12 15:37:03.587251: val_loss -0.2154 
2025-11-12 15:37:03.587391: Pseudo dice [0.745] 
2025-11-12 15:37:03.587600: Epoch time: 225.99 s 
2025-11-12 15:37:05.050924:  
2025-11-12 15:37:05.051356: Epoch 95 
2025-11-12 15:37:05.051498: Current learning rate: 2e-05 
2025-11-12 15:40:51.235838: train_loss -0.5262 
2025-11-12 15:40:51.236156: val_loss -0.2291 
2025-11-12 15:40:51.236263: Pseudo dice [0.7592] 
2025-11-12 15:40:51.236387: Epoch time: 226.19 s 
2025-11-12 15:40:52.634847:  
2025-11-12 15:40:52.635138: Epoch 96 
2025-11-12 15:40:52.635324: Current learning rate: 2e-05 
2025-11-12 15:44:38.295236: train_loss -0.5343 
2025-11-12 15:44:38.295722: val_loss -0.2142 
2025-11-12 15:44:38.295830: Pseudo dice [0.7324] 
2025-11-12 15:44:38.295953: Epoch time: 225.66 s 
2025-11-12 15:44:39.984529:  
2025-11-12 15:44:39.984887: Epoch 97 
2025-11-12 15:44:39.985093: Current learning rate: 1e-05 
2025-11-12 15:48:26.473577: train_loss -0.514 
2025-11-12 15:48:26.473955: val_loss -0.2964 
2025-11-12 15:48:26.474097: Pseudo dice [0.7702] 
2025-11-12 15:48:26.474265: Epoch time: 226.49 s 
2025-11-12 15:48:27.948386:  
2025-11-12 15:48:27.948794: Epoch 98 
2025-11-12 15:48:27.948964: Current learning rate: 1e-05 
2025-11-12 15:52:14.584742: train_loss -0.504 
2025-11-12 15:52:14.585195: val_loss -0.1831 
2025-11-12 15:52:14.585306: Pseudo dice [0.742] 
2025-11-12 15:52:14.585431: Epoch time: 226.64 s 
2025-11-12 15:52:16.030421:  
2025-11-12 15:52:16.030861: Epoch 99 
2025-11-12 15:52:16.031001: Current learning rate: 0.0 
2025-11-12 15:56:02.420007: train_loss -0.521 
2025-11-12 15:56:02.420368: val_loss -0.2407 
2025-11-12 15:56:02.420472: Pseudo dice [0.7519] 
2025-11-12 15:56:02.420591: Epoch time: 226.39 s 
2025-11-12 15:56:04.875080: Training done. 
2025-11-12 15:56:04.902910: Using splits from existing split file: /data/CXY/g/szy/data/nnUNet_preprocessed/Dataset502_DGAGA/splits_final.json 
2025-11-12 15:56:04.903661: The split file contains 5 splits. 
2025-11-12 15:56:04.903748: Desired fold for training: 3 
2025-11-12 15:56:04.903859: This split has 63 training and 16 validation cases. 
2025-11-12 15:56:04.904052: predicting 030406C_2-20x-roi6 
2025-11-12 15:56:06.161223: 030406C_2-20x-roi6, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 15:58:32.087779: predicting 030907-20x-roi1 
2025-11-12 15:58:33.062252: 030907-20x-roi1, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:00:11.252753: predicting 030979-20x-roi6 
2025-11-12 16:00:12.183801: 030979-20x-roi6, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:01:50.542118: predicting 032112-20x-roi3 
2025-11-12 16:01:51.551661: 032112-20x-roi3, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:03:30.206744: predicting 032112-20x-roi6 
2025-11-12 16:03:31.202746: 032112-20x-roi6, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:05:09.695989: predicting 032370B_2-20x-roi2 
2025-11-12 16:05:10.676974: 032370B_2-20x-roi2, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:06:48.444634: predicting 032979-20x-roi5 
2025-11-12 16:06:49.442643: 032979-20x-roi5, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:08:27.927339: predicting 033629-20x-roi10 
2025-11-12 16:08:28.886988: 033629-20x-roi10, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:10:11.597522: predicting 034004A2-20x-roi1 
2025-11-12 16:10:12.575197: 034004A2-20x-roi1, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:11:50.750930: predicting 040483-20x-roi4 
2025-11-12 16:11:51.822953: 040483-20x-roi4, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:13:29.944158: predicting 041602_2-20x-roi1 
2025-11-12 16:13:30.920235: 041602_2-20x-roi1, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:15:09.207779: predicting 042145-20x-roi2 
2025-11-12 16:15:10.135878: 042145-20x-roi2, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:16:48.225544: predicting 042189C_2-20x-roi3 
2025-11-12 16:16:49.165734: 042189C_2-20x-roi3, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:18:27.527045: predicting 042189C_2-20x-roi9 
2025-11-12 16:18:28.505725: 042189C_2-20x-roi9, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:20:06.968436: predicting 050323_2-20x-roi4 
2025-11-12 16:20:08.017346: 050323_2-20x-roi4, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:21:46.384154: predicting 050875-20x-roi2 
2025-11-12 16:21:47.332756: 050875-20x-roi2, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-12 16:23:34.886588: Validation complete 
2025-11-12 16:23:34.886787: Mean Validation Dice:  0.7392418089540639 
