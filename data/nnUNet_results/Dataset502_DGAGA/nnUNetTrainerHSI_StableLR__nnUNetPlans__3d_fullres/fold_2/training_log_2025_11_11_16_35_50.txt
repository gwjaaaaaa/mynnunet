
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-11-11 16:35:51.306595: Using torch.compile... 
2025-11-11 16:35:52.726566: do_dummy_2d_data_aug: False 
2025-11-11 16:35:52.727419: Using splits from existing split file: /data/CXY/g/szy/data/nnUNet_preprocessed/Dataset502_DGAGA/splits_final.json 
2025-11-11 16:35:52.727644: The split file contains 5 splits. 
2025-11-11 16:35:52.727710: Desired fold for training: 2 
2025-11-11 16:35:52.727773: This split has 63 training and 16 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [256, 256, 32], 'median_image_size_in_voxels': [1280.0, 1024.0, 60.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': <class 'torch.nn.modules.conv.Conv3d'>, 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1], [2, 2, 1], [2, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>, 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': <class 'torch.nn.modules.activation.LeakyReLU'>, 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset502_DGAGA', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [1280, 1024, 60], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1.0, 'mean': 0.515815258026123, 'median': 0.5421549081802368, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 1.0, 'std': 0.29032525420188904}}} 
 
2025-11-11 16:35:57.009676: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-11-11 16:35:57.024046:  
2025-11-11 16:35:57.024651: Epoch 0 
2025-11-11 16:35:57.024980: Current learning rate: 0.0003 
2025-11-11 16:40:33.676203: train_loss 0.1882 
2025-11-11 16:40:33.676539: val_loss 0.1129 
2025-11-11 16:40:33.676662: Pseudo dice [0.5129] 
2025-11-11 16:40:33.676790: Epoch time: 276.66 s 
2025-11-11 16:40:33.676890: Yayy! New best EMA pseudo Dice: 0.5129 
2025-11-11 16:40:35.746289:  
2025-11-11 16:40:35.746627: Epoch 1 
2025-11-11 16:40:35.746788: Current learning rate: 0.0003 
2025-11-11 16:42:59.438677: train_loss 0.0491 
2025-11-11 16:42:59.439071: val_loss 0.0332 
2025-11-11 16:42:59.439177: Pseudo dice [0.5783] 
2025-11-11 16:42:59.439295: Epoch time: 143.69 s 
2025-11-11 16:42:59.439386: Yayy! New best EMA pseudo Dice: 0.5194 
2025-11-11 16:43:03.284331:  
2025-11-11 16:43:03.284676: Epoch 2 
2025-11-11 16:43:03.284866: Current learning rate: 0.00029 
2025-11-11 16:45:19.944077: train_loss 0.0133 
2025-11-11 16:45:19.944452: val_loss -0.0108 
2025-11-11 16:45:19.944606: Pseudo dice [0.5931] 
2025-11-11 16:45:19.944724: Epoch time: 136.66 s 
2025-11-11 16:45:19.944818: Yayy! New best EMA pseudo Dice: 0.5268 
2025-11-11 16:45:24.329901:  
2025-11-11 16:45:24.330310: Epoch 3 
2025-11-11 16:45:24.330454: Current learning rate: 0.00029 
2025-11-11 16:47:39.367286: train_loss -0.0499 
2025-11-11 16:47:39.367801: val_loss -0.0468 
2025-11-11 16:47:39.367920: Pseudo dice [0.6057] 
2025-11-11 16:47:39.368062: Epoch time: 135.04 s 
2025-11-11 16:47:39.368163: Yayy! New best EMA pseudo Dice: 0.5347 
2025-11-11 16:47:43.750025:  
2025-11-11 16:47:43.750399: Epoch 4 
2025-11-11 16:47:43.750603: Current learning rate: 0.00029 
2025-11-11 16:50:00.555681: train_loss -0.0612 
2025-11-11 16:50:00.556093: val_loss -0.1175 
2025-11-11 16:50:00.556203: Pseudo dice [0.6727] 
2025-11-11 16:50:00.556333: Epoch time: 136.81 s 
2025-11-11 16:50:00.556427: Yayy! New best EMA pseudo Dice: 0.5485 
2025-11-11 16:50:05.140456:  
2025-11-11 16:50:05.140850: Epoch 5 
2025-11-11 16:50:05.141058: Current learning rate: 0.00029 
2025-11-11 16:52:15.877221: train_loss -0.0628 
2025-11-11 16:52:15.877613: val_loss -0.1465 
2025-11-11 16:52:15.877721: Pseudo dice [0.6702] 
2025-11-11 16:52:15.877848: Epoch time: 130.74 s 
2025-11-11 16:52:15.877938: Yayy! New best EMA pseudo Dice: 0.5607 
2025-11-11 16:52:19.839344:  
2025-11-11 16:52:19.839737: Epoch 6 
2025-11-11 16:52:19.839904: Current learning rate: 0.00028 
2025-11-11 16:54:31.750623: train_loss -0.1286 
2025-11-11 16:54:31.751445: val_loss -0.1876 
2025-11-11 16:54:31.751659: Pseudo dice [0.6954] 
2025-11-11 16:54:31.751780: Epoch time: 131.91 s 
2025-11-11 16:54:31.751877: Yayy! New best EMA pseudo Dice: 0.5741 
2025-11-11 16:54:36.245570:  
2025-11-11 16:54:36.245934: Epoch 7 
2025-11-11 16:54:36.246248: Current learning rate: 0.00028 
2025-11-11 16:56:46.260607: train_loss -0.1173 
2025-11-11 16:56:46.260923: val_loss -0.0943 
2025-11-11 16:56:46.261033: Pseudo dice [0.6599] 
2025-11-11 16:56:46.261154: Epoch time: 130.02 s 
2025-11-11 16:56:46.261242: Yayy! New best EMA pseudo Dice: 0.5827 
2025-11-11 16:56:50.048759:  
2025-11-11 16:56:50.049042: Epoch 8 
2025-11-11 16:56:50.049233: Current learning rate: 0.00028 
2025-11-11 16:58:55.175118: train_loss -0.131 
2025-11-11 16:58:55.175457: val_loss -0.1468 
2025-11-11 16:58:55.175593: Pseudo dice [0.6669] 
2025-11-11 16:58:55.175890: Epoch time: 125.13 s 
2025-11-11 16:58:55.176082: Yayy! New best EMA pseudo Dice: 0.5911 
2025-11-11 16:58:59.692945:  
2025-11-11 16:58:59.693381: Epoch 9 
2025-11-11 16:58:59.693527: Current learning rate: 0.00028 
2025-11-11 17:01:14.265306: train_loss -0.1787 
2025-11-11 17:01:14.265672: val_loss -0.1499 
2025-11-11 17:01:14.265778: Pseudo dice [0.6835] 
2025-11-11 17:01:14.265892: Epoch time: 134.58 s 
2025-11-11 17:01:14.265981: Yayy! New best EMA pseudo Dice: 0.6004 
2025-11-11 17:01:19.759607:  
2025-11-11 17:01:19.759972: Epoch 10 
2025-11-11 17:01:19.760128: Current learning rate: 0.00027 
2025-11-11 17:03:27.667824: train_loss -0.1582 
2025-11-11 17:03:27.668171: val_loss -0.1803 
2025-11-11 17:03:27.668273: Pseudo dice [0.7083] 
2025-11-11 17:03:27.668390: Epoch time: 127.91 s 
2025-11-11 17:03:27.668478: Yayy! New best EMA pseudo Dice: 0.6111 
2025-11-11 17:03:31.673258:  
2025-11-11 17:03:31.673569: Epoch 11 
2025-11-11 17:03:31.673771: Current learning rate: 0.00027 
2025-11-11 17:05:37.476499: train_loss -0.1738 
2025-11-11 17:05:37.476868: val_loss -0.2685 
2025-11-11 17:05:37.476974: Pseudo dice [0.7266] 
2025-11-11 17:05:37.477091: Epoch time: 125.81 s 
2025-11-11 17:05:37.477179: Yayy! New best EMA pseudo Dice: 0.6227 
2025-11-11 17:05:41.137424:  
2025-11-11 17:05:41.137817: Epoch 12 
2025-11-11 17:05:41.137957: Current learning rate: 0.00027 
2025-11-11 17:07:47.340029: train_loss -0.193 
2025-11-11 17:07:47.340398: val_loss -0.2327 
2025-11-11 17:07:47.340515: Pseudo dice [0.7107] 
2025-11-11 17:07:47.340633: Epoch time: 126.2 s 
2025-11-11 17:07:47.340731: Yayy! New best EMA pseudo Dice: 0.6315 
2025-11-11 17:07:51.273242:  
2025-11-11 17:07:51.273633: Epoch 13 
2025-11-11 17:07:51.273942: Current learning rate: 0.00026 
2025-11-11 17:10:03.258323: train_loss -0.1877 
2025-11-11 17:10:03.258729: val_loss -0.2278 
2025-11-11 17:10:03.258840: Pseudo dice [0.7075] 
2025-11-11 17:10:03.258966: Epoch time: 131.99 s 
2025-11-11 17:10:03.259146: Yayy! New best EMA pseudo Dice: 0.6391 
2025-11-11 17:10:07.041854:  
2025-11-11 17:10:07.042356: Epoch 14 
2025-11-11 17:10:07.042623: Current learning rate: 0.00026 
2025-11-11 17:12:13.092608: train_loss -0.2034 
2025-11-11 17:12:13.093001: val_loss -0.2755 
2025-11-11 17:12:13.093102: Pseudo dice [0.7265] 
2025-11-11 17:12:13.093218: Epoch time: 126.05 s 
2025-11-11 17:12:13.093314: Yayy! New best EMA pseudo Dice: 0.6478 
2025-11-11 17:12:17.628723:  
2025-11-11 17:12:17.629130: Epoch 15 
2025-11-11 17:12:17.629399: Current learning rate: 0.00026 
2025-11-11 17:14:26.402191: train_loss -0.2118 
2025-11-11 17:14:26.402625: val_loss -0.2159 
2025-11-11 17:14:26.402951: Pseudo dice [0.7113] 
2025-11-11 17:14:26.403128: Epoch time: 128.78 s 
2025-11-11 17:14:26.403260: Yayy! New best EMA pseudo Dice: 0.6542 
2025-11-11 17:14:30.357118:  
2025-11-11 17:14:30.357460: Epoch 16 
2025-11-11 17:14:30.357652: Current learning rate: 0.00026 
2025-11-11 17:16:39.047981: train_loss -0.2201 
2025-11-11 17:16:39.048631: val_loss -0.1821 
2025-11-11 17:16:39.048776: Pseudo dice [0.7062] 
2025-11-11 17:16:39.048918: Epoch time: 128.69 s 
2025-11-11 17:16:39.049021: Yayy! New best EMA pseudo Dice: 0.6594 
2025-11-11 17:16:42.767411:  
2025-11-11 17:16:42.767774: Epoch 17 
2025-11-11 17:16:42.768029: Current learning rate: 0.00025 
2025-11-11 17:18:49.265183: train_loss -0.1818 
2025-11-11 17:18:49.265850: val_loss -0.24 
2025-11-11 17:18:49.268290: Pseudo dice [0.7122] 
2025-11-11 17:18:49.268556: Epoch time: 126.5 s 
2025-11-11 17:18:49.268732: Yayy! New best EMA pseudo Dice: 0.6647 
2025-11-11 17:18:54.045473:  
2025-11-11 17:18:54.045771: Epoch 18 
2025-11-11 17:18:54.045921: Current learning rate: 0.00025 
2025-11-11 17:21:11.862815: train_loss -0.2068 
2025-11-11 17:21:11.863158: val_loss -0.2389 
2025-11-11 17:21:11.863273: Pseudo dice [0.6994] 
2025-11-11 17:21:11.863391: Epoch time: 137.82 s 
2025-11-11 17:21:11.863483: Yayy! New best EMA pseudo Dice: 0.6681 
2025-11-11 17:21:15.527036:  
2025-11-11 17:21:15.527384: Epoch 19 
2025-11-11 17:21:15.527522: Current learning rate: 0.00025 
2025-11-11 17:23:26.426756: train_loss -0.2692 
2025-11-11 17:23:26.430015: val_loss -0.2816 
2025-11-11 17:23:26.430484: Pseudo dice [0.6987] 
2025-11-11 17:23:26.430962: Epoch time: 130.9 s 
2025-11-11 17:23:26.431487: Yayy! New best EMA pseudo Dice: 0.6712 
2025-11-11 17:23:30.896013:  
2025-11-11 17:23:30.896440: Epoch 20 
2025-11-11 17:23:30.896608: Current learning rate: 0.00025 
2025-11-11 17:25:36.533930: train_loss -0.2456 
2025-11-11 17:25:36.534407: val_loss -0.2287 
2025-11-11 17:25:36.534551: Pseudo dice [0.7023] 
2025-11-11 17:25:36.534785: Epoch time: 125.64 s 
2025-11-11 17:25:36.534907: Yayy! New best EMA pseudo Dice: 0.6743 
2025-11-11 17:25:40.413076:  
2025-11-11 17:25:40.413496: Epoch 21 
2025-11-11 17:25:40.413839: Current learning rate: 0.00024 
2025-11-11 17:27:56.552825: train_loss -0.2521 
2025-11-11 17:27:56.553128: val_loss -0.2589 
2025-11-11 17:27:56.553232: Pseudo dice [0.7219] 
2025-11-11 17:27:56.553345: Epoch time: 136.14 s 
2025-11-11 17:27:56.553431: Yayy! New best EMA pseudo Dice: 0.6791 
2025-11-11 17:28:00.665070:  
2025-11-11 17:28:00.665488: Epoch 22 
2025-11-11 17:28:00.665682: Current learning rate: 0.00024 
2025-11-11 17:30:14.037624: train_loss -0.2524 
2025-11-11 17:30:14.038110: val_loss -0.233 
2025-11-11 17:30:14.038240: Pseudo dice [0.7056] 
2025-11-11 17:30:14.038359: Epoch time: 133.38 s 
2025-11-11 17:30:14.038446: Yayy! New best EMA pseudo Dice: 0.6817 
2025-11-11 17:30:18.400657:  
2025-11-11 17:30:18.401089: Epoch 23 
2025-11-11 17:30:18.401233: Current learning rate: 0.00024 
2025-11-11 17:32:34.677564: train_loss -0.2899 
2025-11-11 17:32:34.677936: val_loss -0.2421 
2025-11-11 17:32:34.678048: Pseudo dice [0.6798] 
2025-11-11 17:32:34.678190: Epoch time: 136.28 s 
2025-11-11 17:32:36.130382:  
2025-11-11 17:32:36.130819: Epoch 24 
2025-11-11 17:32:36.131066: Current learning rate: 0.00023 
2025-11-11 17:34:49.305675: train_loss -0.2566 
2025-11-11 17:34:49.305981: val_loss -0.2595 
2025-11-11 17:34:49.306088: Pseudo dice [0.6998] 
2025-11-11 17:34:49.306222: Epoch time: 133.18 s 
2025-11-11 17:34:49.306318: Yayy! New best EMA pseudo Dice: 0.6834 
2025-11-11 17:34:56.064163:  
2025-11-11 17:34:56.064510: Epoch 25 
2025-11-11 17:34:56.064681: Current learning rate: 0.00023 
2025-11-11 17:37:05.785169: train_loss -0.2379 
2025-11-11 17:37:05.785529: val_loss -0.2133 
2025-11-11 17:37:05.785639: Pseudo dice [0.6918] 
2025-11-11 17:37:05.785752: Epoch time: 129.72 s 
2025-11-11 17:37:05.785840: Yayy! New best EMA pseudo Dice: 0.6842 
2025-11-11 17:37:09.570309:  
2025-11-11 17:37:09.570674: Epoch 26 
2025-11-11 17:37:09.570834: Current learning rate: 0.00023 
2025-11-11 17:39:21.982489: train_loss -0.2489 
2025-11-11 17:39:21.982867: val_loss -0.2567 
2025-11-11 17:39:21.983032: Pseudo dice [0.7259] 
2025-11-11 17:39:21.983150: Epoch time: 132.41 s 
2025-11-11 17:39:21.983240: Yayy! New best EMA pseudo Dice: 0.6884 
2025-11-11 17:39:26.771183:  
2025-11-11 17:39:26.771526: Epoch 27 
2025-11-11 17:39:26.771678: Current learning rate: 0.00023 
2025-11-11 17:41:33.904177: train_loss -0.2954 
2025-11-11 17:41:33.904609: val_loss -0.2668 
2025-11-11 17:41:33.904726: Pseudo dice [0.7182] 
2025-11-11 17:41:33.904843: Epoch time: 127.14 s 
2025-11-11 17:41:33.904933: Yayy! New best EMA pseudo Dice: 0.6914 
2025-11-11 17:41:37.665418:  
2025-11-11 17:41:37.665680: Epoch 28 
2025-11-11 17:41:37.665905: Current learning rate: 0.00022 
2025-11-11 17:43:45.319720: train_loss -0.2727 
2025-11-11 17:43:45.320081: val_loss -0.3569 
2025-11-11 17:43:45.320179: Pseudo dice [0.7568] 
2025-11-11 17:43:45.320293: Epoch time: 127.66 s 
2025-11-11 17:43:45.320396: Yayy! New best EMA pseudo Dice: 0.6979 
2025-11-11 17:43:49.181321:  
2025-11-11 17:43:49.181646: Epoch 29 
2025-11-11 17:43:49.181820: Current learning rate: 0.00022 
2025-11-11 17:45:57.713873: train_loss -0.3126 
2025-11-11 17:45:57.714201: val_loss -0.3042 
2025-11-11 17:45:57.714312: Pseudo dice [0.7318] 
2025-11-11 17:45:57.714479: Epoch time: 128.53 s 
2025-11-11 17:45:57.714573: Yayy! New best EMA pseudo Dice: 0.7013 
2025-11-11 17:46:01.917750:  
2025-11-11 17:46:01.918115: Epoch 30 
2025-11-11 17:46:01.918310: Current learning rate: 0.00022 
2025-11-11 17:48:07.330592: train_loss -0.2978 
2025-11-11 17:48:07.331011: val_loss -0.29 
2025-11-11 17:48:07.331249: Pseudo dice [0.7262] 
2025-11-11 17:48:07.331425: Epoch time: 125.42 s 
2025-11-11 17:48:07.331522: Yayy! New best EMA pseudo Dice: 0.7038 
2025-11-11 17:48:10.845479:  
2025-11-11 17:48:10.845843: Epoch 31 
2025-11-11 17:48:10.845992: Current learning rate: 0.00021 
2025-11-11 17:50:17.313490: train_loss -0.2776 
2025-11-11 17:50:17.313970: val_loss -0.2773 
2025-11-11 17:50:17.314236: Pseudo dice [0.7138] 
2025-11-11 17:50:17.314353: Epoch time: 126.47 s 
2025-11-11 17:50:17.314457: Yayy! New best EMA pseudo Dice: 0.7048 
2025-11-11 17:50:20.693791:  
2025-11-11 17:50:20.694100: Epoch 32 
2025-11-11 17:50:20.694311: Current learning rate: 0.00021 
2025-11-11 17:52:31.372350: train_loss -0.2849 
2025-11-11 17:52:31.372752: val_loss -0.1804 
2025-11-11 17:52:31.372968: Pseudo dice [0.6341] 
2025-11-11 17:52:31.373124: Epoch time: 130.68 s 
2025-11-11 17:52:32.700918:  
2025-11-11 17:52:32.701284: Epoch 33 
2025-11-11 17:52:32.701459: Current learning rate: 0.00021 
2025-11-11 17:54:40.851264: train_loss -0.3133 
2025-11-11 17:54:40.851775: val_loss -0.2691 
2025-11-11 17:54:40.851890: Pseudo dice [0.7023] 
2025-11-11 17:54:40.852007: Epoch time: 128.15 s 
2025-11-11 17:54:42.208214:  
2025-11-11 17:54:42.208526: Epoch 34 
2025-11-11 17:54:42.208724: Current learning rate: 0.00021 
2025-11-11 17:56:46.050853: train_loss -0.2809 
2025-11-11 17:56:46.051200: val_loss -0.2853 
2025-11-11 17:56:46.051307: Pseudo dice [0.7472] 
2025-11-11 17:56:46.051434: Epoch time: 123.84 s 
2025-11-11 17:56:47.447804:  
2025-11-11 17:56:47.448162: Epoch 35 
2025-11-11 17:56:47.448329: Current learning rate: 0.0002 
2025-11-11 17:58:59.321003: train_loss -0.3235 
2025-11-11 17:58:59.321472: val_loss -0.2295 
2025-11-11 17:58:59.321581: Pseudo dice [0.7005] 
2025-11-11 17:58:59.321701: Epoch time: 131.88 s 
2025-11-11 17:59:00.733986:  
2025-11-11 17:59:00.734384: Epoch 36 
2025-11-11 17:59:00.734523: Current learning rate: 0.0002 
2025-11-11 18:01:07.881517: train_loss -0.3512 
2025-11-11 18:01:07.881945: val_loss -0.1978 
2025-11-11 18:01:07.882119: Pseudo dice [0.6896] 
2025-11-11 18:01:07.882259: Epoch time: 127.15 s 
2025-11-11 18:01:09.282047:  
2025-11-11 18:01:09.282468: Epoch 37 
2025-11-11 18:01:09.282632: Current learning rate: 0.0002 
2025-11-11 18:03:18.330987: train_loss -0.3293 
2025-11-11 18:03:18.331295: val_loss -0.2376 
2025-11-11 18:03:18.331512: Pseudo dice [0.6996] 
2025-11-11 18:03:18.331629: Epoch time: 129.05 s 
2025-11-11 18:03:19.754000:  
2025-11-11 18:03:19.754385: Epoch 38 
2025-11-11 18:03:19.754589: Current learning rate: 0.0002 
2025-11-11 18:05:30.184974: train_loss -0.3072 
2025-11-11 18:05:30.185378: val_loss -0.3341 
2025-11-11 18:05:30.185503: Pseudo dice [0.7523] 
2025-11-11 18:05:30.185744: Epoch time: 130.43 s 
2025-11-11 18:05:30.185871: Yayy! New best EMA pseudo Dice: 0.7064 
2025-11-11 18:05:33.826433:  
2025-11-11 18:05:33.826749: Epoch 39 
2025-11-11 18:05:33.826921: Current learning rate: 0.00019 
2025-11-11 18:07:45.053300: train_loss -0.3095 
2025-11-11 18:07:45.053766: val_loss -0.2229 
2025-11-11 18:07:45.053971: Pseudo dice [0.687] 
2025-11-11 18:07:45.054087: Epoch time: 131.23 s 
2025-11-11 18:07:46.464341:  
2025-11-11 18:07:46.464725: Epoch 40 
2025-11-11 18:07:46.464899: Current learning rate: 0.00019 
2025-11-11 18:10:16.346783: train_loss -0.3147 
2025-11-11 18:10:16.347252: val_loss -0.2234 
2025-11-11 18:10:16.347357: Pseudo dice [0.7257] 
2025-11-11 18:10:16.347475: Epoch time: 149.88 s 
2025-11-11 18:10:16.347567: Yayy! New best EMA pseudo Dice: 0.7066 
2025-11-11 18:10:20.132839:  
2025-11-11 18:10:20.133202: Epoch 41 
2025-11-11 18:10:20.133341: Current learning rate: 0.00019 
2025-11-11 18:12:33.849280: train_loss -0.3404 
2025-11-11 18:12:33.849685: val_loss -0.3432 
2025-11-11 18:12:33.849790: Pseudo dice [0.7541] 
2025-11-11 18:12:33.849906: Epoch time: 133.72 s 
2025-11-11 18:12:33.849997: Yayy! New best EMA pseudo Dice: 0.7113 
2025-11-11 18:12:37.616781:  
2025-11-11 18:12:37.617164: Epoch 42 
2025-11-11 18:12:37.617380: Current learning rate: 0.00018 
2025-11-11 18:14:52.634912: train_loss -0.3226 
2025-11-11 18:14:52.635210: val_loss -0.3532 
2025-11-11 18:14:52.635330: Pseudo dice [0.7516] 
2025-11-11 18:14:52.635442: Epoch time: 135.02 s 
2025-11-11 18:14:52.635528: Yayy! New best EMA pseudo Dice: 0.7154 
2025-11-11 18:14:56.237495:  
2025-11-11 18:14:56.237896: Epoch 43 
2025-11-11 18:14:56.238069: Current learning rate: 0.00018 
2025-11-11 18:17:12.776238: train_loss -0.376 
2025-11-11 18:17:12.776648: val_loss -0.2123 
2025-11-11 18:17:12.776754: Pseudo dice [0.6983] 
2025-11-11 18:17:12.776881: Epoch time: 136.54 s 
2025-11-11 18:17:14.208669:  
2025-11-11 18:17:14.209020: Epoch 44 
2025-11-11 18:17:14.209200: Current learning rate: 0.00018 
2025-11-11 18:19:20.218343: train_loss -0.3465 
2025-11-11 18:19:20.218754: val_loss -0.2667 
2025-11-11 18:19:20.218903: Pseudo dice [0.7262] 
2025-11-11 18:19:20.219020: Epoch time: 126.01 s 
2025-11-11 18:19:21.565761:  
2025-11-11 18:19:21.566111: Epoch 45 
2025-11-11 18:19:21.566415: Current learning rate: 0.00018 
2025-11-11 18:21:33.773735: train_loss -0.3727 
2025-11-11 18:21:33.774342: val_loss -0.3506 
2025-11-11 18:21:33.774462: Pseudo dice [0.759] 
2025-11-11 18:21:33.774854: Epoch time: 132.21 s 
2025-11-11 18:21:33.774983: Yayy! New best EMA pseudo Dice: 0.7193 
2025-11-11 18:21:37.624780:  
2025-11-11 18:21:37.625214: Epoch 46 
2025-11-11 18:21:37.625485: Current learning rate: 0.00017 
2025-11-11 18:23:51.249982: train_loss -0.3556 
2025-11-11 18:23:51.250459: val_loss -0.2947 
2025-11-11 18:23:51.250578: Pseudo dice [0.7296] 
2025-11-11 18:23:51.250703: Epoch time: 133.63 s 
2025-11-11 18:23:51.250797: Yayy! New best EMA pseudo Dice: 0.7204 
2025-11-11 18:23:55.415154:  
2025-11-11 18:23:55.415544: Epoch 47 
2025-11-11 18:23:55.415719: Current learning rate: 0.00017 
2025-11-11 18:26:17.733268: train_loss -0.365 
2025-11-11 18:26:17.733638: val_loss -0.2374 
2025-11-11 18:26:17.733766: Pseudo dice [0.707] 
2025-11-11 18:26:17.734043: Epoch time: 142.32 s 
2025-11-11 18:26:19.399784:  
2025-11-11 18:26:19.400126: Epoch 48 
2025-11-11 18:26:19.400257: Current learning rate: 0.00017 
2025-11-11 18:29:16.602280: train_loss -0.3566 
2025-11-11 18:29:16.602722: val_loss -0.3203 
2025-11-11 18:29:16.602852: Pseudo dice [0.7415] 
2025-11-11 18:29:16.603001: Epoch time: 177.2 s 
2025-11-11 18:29:16.603161: Yayy! New best EMA pseudo Dice: 0.7213 
2025-11-11 18:29:22.580518:  
2025-11-11 18:29:22.580760: Epoch 49 
2025-11-11 18:29:22.580899: Current learning rate: 0.00016 
2025-11-11 18:32:29.402520: train_loss -0.3694 
2025-11-11 18:32:29.402977: val_loss -0.2912 
2025-11-11 18:32:29.403193: Pseudo dice [0.7257] 
2025-11-11 18:32:29.403313: Epoch time: 186.82 s 
2025-11-11 18:32:30.028405: Yayy! New best EMA pseudo Dice: 0.7217 
2025-11-11 18:32:34.972567:  
2025-11-11 18:32:34.972895: Epoch 50 
2025-11-11 18:32:34.973074: Current learning rate: 0.00016 
2025-11-11 18:35:27.503042: train_loss -0.3843 
2025-11-11 18:35:27.503509: val_loss -0.3087 
2025-11-11 18:35:27.503621: Pseudo dice [0.7289] 
2025-11-11 18:35:27.503823: Epoch time: 172.54 s 
2025-11-11 18:35:27.503915: Yayy! New best EMA pseudo Dice: 0.7224 
2025-11-11 18:35:32.084186:  
2025-11-11 18:35:32.084656: Epoch 51 
2025-11-11 18:35:32.084797: Current learning rate: 0.00016 
2025-11-11 18:37:43.187448: train_loss -0.3688 
2025-11-11 18:37:43.187806: val_loss -0.3004 
2025-11-11 18:37:43.187984: Pseudo dice [0.7323] 
2025-11-11 18:37:43.188107: Epoch time: 131.11 s 
2025-11-11 18:37:43.188199: Yayy! New best EMA pseudo Dice: 0.7234 
2025-11-11 18:37:47.561911:  
2025-11-11 18:37:47.562306: Epoch 52 
2025-11-11 18:37:47.562465: Current learning rate: 0.00015 
2025-11-11 18:39:57.742696: train_loss -0.3772 
2025-11-11 18:39:57.743097: val_loss -0.3461 
2025-11-11 18:39:57.743221: Pseudo dice [0.7504] 
2025-11-11 18:39:57.743343: Epoch time: 130.18 s 
2025-11-11 18:39:57.743449: Yayy! New best EMA pseudo Dice: 0.7261 
2025-11-11 18:40:02.270796:  
2025-11-11 18:40:02.271133: Epoch 53 
2025-11-11 18:40:02.271299: Current learning rate: 0.00015 
2025-11-11 18:42:13.460919: train_loss -0.3938 
2025-11-11 18:42:13.461278: val_loss -0.3935 
2025-11-11 18:42:13.461421: Pseudo dice [0.7795] 
2025-11-11 18:42:13.461567: Epoch time: 131.19 s 
2025-11-11 18:42:13.461689: Yayy! New best EMA pseudo Dice: 0.7315 
2025-11-11 18:42:17.782238:  
2025-11-11 18:42:17.782558: Epoch 54 
2025-11-11 18:42:17.782714: Current learning rate: 0.00015 
2025-11-11 18:44:24.222143: train_loss -0.406 
2025-11-11 18:44:24.222627: val_loss -0.3906 
2025-11-11 18:44:24.222732: Pseudo dice [0.7787] 
2025-11-11 18:44:24.222853: Epoch time: 126.44 s 
2025-11-11 18:44:24.222946: Yayy! New best EMA pseudo Dice: 0.7362 
2025-11-11 18:44:28.300787:  
2025-11-11 18:44:28.301191: Epoch 55 
2025-11-11 18:44:28.301326: Current learning rate: 0.00015 
2025-11-11 18:46:35.580522: train_loss -0.3762 
2025-11-11 18:46:35.580944: val_loss -0.3607 
2025-11-11 18:46:35.581048: Pseudo dice [0.76] 
2025-11-11 18:46:35.581161: Epoch time: 127.28 s 
2025-11-11 18:46:35.581247: Yayy! New best EMA pseudo Dice: 0.7386 
2025-11-11 18:46:39.380474:  
2025-11-11 18:46:39.380810: Epoch 56 
2025-11-11 18:46:39.380943: Current learning rate: 0.00014 
2025-11-11 18:49:25.582439: train_loss -0.3857 
2025-11-11 18:49:25.582904: val_loss -0.3044 
2025-11-11 18:49:25.583024: Pseudo dice [0.7351] 
2025-11-11 18:49:25.583146: Epoch time: 166.2 s 
2025-11-11 18:49:27.247579:  
2025-11-11 18:49:27.247996: Epoch 57 
2025-11-11 18:49:27.248174: Current learning rate: 0.00014 
2025-11-11 18:52:39.932515: train_loss -0.4086 
2025-11-11 18:52:39.932899: val_loss -0.3663 
2025-11-11 18:52:39.933043: Pseudo dice [0.7604] 
2025-11-11 18:52:39.933156: Epoch time: 192.69 s 
2025-11-11 18:52:39.933244: Yayy! New best EMA pseudo Dice: 0.7404 
2025-11-11 18:52:43.810991:  
2025-11-11 18:52:43.811372: Epoch 58 
2025-11-11 18:52:43.811548: Current learning rate: 0.00014 
2025-11-11 18:55:58.366819: train_loss -0.4258 
2025-11-11 18:55:58.367321: val_loss -0.3012 
2025-11-11 18:55:58.367455: Pseudo dice [0.7337] 
2025-11-11 18:55:58.367611: Epoch time: 194.56 s 
2025-11-11 18:55:59.933949:  
2025-11-11 18:55:59.934281: Epoch 59 
2025-11-11 18:55:59.934466: Current learning rate: 0.00013 
2025-11-11 18:58:09.936405: train_loss -0.4152 
2025-11-11 18:58:09.936737: val_loss -0.4182 
2025-11-11 18:58:09.936850: Pseudo dice [0.778] 
2025-11-11 18:58:09.936973: Epoch time: 130.01 s 
2025-11-11 18:58:09.937072: Yayy! New best EMA pseudo Dice: 0.7436 
2025-11-11 18:58:13.537969:  
2025-11-11 18:58:13.538289: Epoch 60 
2025-11-11 18:58:13.538426: Current learning rate: 0.00013 
2025-11-11 19:00:22.765852: train_loss -0.4011 
2025-11-11 19:00:22.766201: val_loss -0.3524 
2025-11-11 19:00:22.766316: Pseudo dice [0.7635] 
2025-11-11 19:00:22.766431: Epoch time: 129.23 s 
2025-11-11 19:00:22.766522: Yayy! New best EMA pseudo Dice: 0.7456 
2025-11-11 19:00:26.747935:  
2025-11-11 19:00:26.748273: Epoch 61 
2025-11-11 19:00:26.748403: Current learning rate: 0.00013 
2025-11-11 19:02:44.730417: train_loss -0.4246 
2025-11-11 19:02:44.730806: val_loss -0.3931 
2025-11-11 19:02:44.730987: Pseudo dice [0.7721] 
2025-11-11 19:02:44.731136: Epoch time: 137.98 s 
2025-11-11 19:02:44.731227: Yayy! New best EMA pseudo Dice: 0.7482 
2025-11-11 19:02:48.450700:  
2025-11-11 19:02:48.451059: Epoch 62 
2025-11-11 19:02:48.451263: Current learning rate: 0.00013 
2025-11-11 19:04:57.737406: train_loss -0.4441 
2025-11-11 19:04:57.737788: val_loss -0.3436 
2025-11-11 19:04:57.737931: Pseudo dice [0.7499] 
2025-11-11 19:04:57.738088: Epoch time: 129.29 s 
2025-11-11 19:04:57.738252: Yayy! New best EMA pseudo Dice: 0.7484 
2025-11-11 19:05:01.762846:  
2025-11-11 19:05:01.763349: Epoch 63 
2025-11-11 19:05:01.763540: Current learning rate: 0.00012 
2025-11-11 19:07:14.145483: train_loss -0.4291 
2025-11-11 19:07:14.145869: val_loss -0.4175 
2025-11-11 19:07:14.146058: Pseudo dice [0.7834] 
2025-11-11 19:07:14.146226: Epoch time: 132.38 s 
2025-11-11 19:07:14.146318: Yayy! New best EMA pseudo Dice: 0.7519 
2025-11-11 19:07:18.315371:  
2025-11-11 19:07:18.315763: Epoch 64 
2025-11-11 19:07:18.315902: Current learning rate: 0.00012 
2025-11-11 19:10:21.640387: train_loss -0.4129 
2025-11-11 19:10:21.640726: val_loss -0.3653 
2025-11-11 19:10:21.640913: Pseudo dice [0.7568] 
2025-11-11 19:10:21.641181: Epoch time: 183.33 s 
2025-11-11 19:10:21.641271: Yayy! New best EMA pseudo Dice: 0.7524 
2025-11-11 19:10:26.053282:  
2025-11-11 19:10:26.053601: Epoch 65 
2025-11-11 19:10:26.053738: Current learning rate: 0.00012 
2025-11-11 19:13:42.791994: train_loss -0.432 
2025-11-11 19:13:42.792338: val_loss -0.3778 
2025-11-11 19:13:42.792535: Pseudo dice [0.7665] 
2025-11-11 19:13:42.792652: Epoch time: 196.74 s 
2025-11-11 19:13:42.792753: Yayy! New best EMA pseudo Dice: 0.7538 
2025-11-11 19:13:47.026616:  
2025-11-11 19:13:47.027078: Epoch 66 
2025-11-11 19:13:47.027243: Current learning rate: 0.00011 
2025-11-11 19:16:30.170190: train_loss -0.4446 
2025-11-11 19:16:30.172332: val_loss -0.2745 
2025-11-11 19:16:30.173676: Pseudo dice [0.7284] 
2025-11-11 19:16:30.174435: Epoch time: 163.15 s 
2025-11-11 19:16:32.892944:  
2025-11-11 19:16:32.893317: Epoch 67 
2025-11-11 19:16:32.893488: Current learning rate: 0.00011 
2025-11-11 19:18:56.471887: train_loss -0.4139 
2025-11-11 19:18:56.472235: val_loss -0.3715 
2025-11-11 19:18:56.472367: Pseudo dice [0.7552] 
2025-11-11 19:18:56.472484: Epoch time: 143.58 s 
2025-11-11 19:18:58.063465:  
2025-11-11 19:18:58.063821: Epoch 68 
2025-11-11 19:18:58.063957: Current learning rate: 0.00011 
2025-11-11 19:21:51.716765: train_loss -0.4451 
2025-11-11 19:21:51.717104: val_loss -0.3747 
2025-11-11 19:21:51.717206: Pseudo dice [0.7678] 
2025-11-11 19:21:51.717332: Epoch time: 173.66 s 
2025-11-11 19:21:53.129412:  
2025-11-11 19:21:53.129861: Epoch 69 
2025-11-11 19:21:53.130018: Current learning rate: 0.0001 
2025-11-11 19:24:05.349092: train_loss -0.4223 
2025-11-11 19:24:05.349574: val_loss -0.3585 
2025-11-11 19:24:05.349703: Pseudo dice [0.7497] 
2025-11-11 19:24:05.349820: Epoch time: 132.22 s 
2025-11-11 19:24:06.831937:  
2025-11-11 19:24:06.832263: Epoch 70 
2025-11-11 19:24:06.832407: Current learning rate: 0.0001 
2025-11-11 19:26:22.792154: train_loss -0.4018 
2025-11-11 19:26:22.792502: val_loss -0.3151 
2025-11-11 19:26:22.792670: Pseudo dice [0.7354] 
2025-11-11 19:26:22.792787: Epoch time: 135.96 s 
2025-11-11 19:26:24.240625:  
2025-11-11 19:26:24.240963: Epoch 71 
2025-11-11 19:26:24.241127: Current learning rate: 0.0001 
2025-11-11 19:28:35.228259: train_loss -0.4527 
2025-11-11 19:28:35.228601: val_loss -0.3562 
2025-11-11 19:28:35.228704: Pseudo dice [0.74] 
2025-11-11 19:28:35.228819: Epoch time: 130.99 s 
2025-11-11 19:28:36.760497:  
2025-11-11 19:28:36.760800: Epoch 72 
2025-11-11 19:28:36.761023: Current learning rate: 0.0001 
2025-11-11 19:30:43.035581: train_loss -0.4457 
2025-11-11 19:30:43.035980: val_loss -0.3655 
2025-11-11 19:30:43.036084: Pseudo dice [0.7558] 
2025-11-11 19:30:43.036204: Epoch time: 126.28 s 
2025-11-11 19:30:44.577657:  
2025-11-11 19:30:44.578139: Epoch 73 
2025-11-11 19:30:44.578429: Current learning rate: 9e-05 
2025-11-11 19:33:49.226932: train_loss -0.4333 
2025-11-11 19:33:49.227346: val_loss -0.3356 
2025-11-11 19:33:49.227478: Pseudo dice [0.756] 
2025-11-11 19:33:49.227623: Epoch time: 184.65 s 
2025-11-11 19:33:50.825997:  
2025-11-11 19:33:50.826484: Epoch 74 
2025-11-11 19:33:50.826660: Current learning rate: 9e-05 
2025-11-11 19:37:06.737497: train_loss -0.4619 
2025-11-11 19:37:06.737902: val_loss -0.2547 
2025-11-11 19:37:06.738076: Pseudo dice [0.6898] 
2025-11-11 19:37:06.738230: Epoch time: 195.92 s 
2025-11-11 19:37:08.272679:  
2025-11-11 19:37:08.273010: Epoch 75 
2025-11-11 19:37:08.273255: Current learning rate: 9e-05 
2025-11-11 19:39:57.541643: train_loss -0.4415 
2025-11-11 19:39:57.541991: val_loss -0.2812 
2025-11-11 19:39:57.542093: Pseudo dice [0.7102] 
2025-11-11 19:39:57.542222: Epoch time: 169.27 s 
2025-11-11 19:39:59.040964:  
2025-11-11 19:39:59.041292: Epoch 76 
2025-11-11 19:39:59.041492: Current learning rate: 8e-05 
2025-11-11 19:42:02.525342: train_loss -0.465 
2025-11-11 19:42:02.525662: val_loss -0.3555 
2025-11-11 19:42:02.525763: Pseudo dice [0.7654] 
2025-11-11 19:42:02.525994: Epoch time: 123.49 s 
2025-11-11 19:42:03.941161:  
2025-11-11 19:42:03.941526: Epoch 77 
2025-11-11 19:42:03.941714: Current learning rate: 8e-05 
2025-11-11 19:45:04.736855: train_loss -0.4923 
2025-11-11 19:45:04.737234: val_loss -0.3908 
2025-11-11 19:45:04.737353: Pseudo dice [0.7645] 
2025-11-11 19:45:04.737497: Epoch time: 180.8 s 
2025-11-11 19:45:06.104089:  
2025-11-11 19:45:06.104479: Epoch 78 
2025-11-11 19:45:06.104647: Current learning rate: 8e-05 
2025-11-11 19:47:11.649582: train_loss -0.488 
2025-11-11 19:47:11.649978: val_loss -0.258 
2025-11-11 19:47:11.650097: Pseudo dice [0.7252] 
2025-11-11 19:47:11.650291: Epoch time: 125.55 s 
2025-11-11 19:47:13.050499:  
2025-11-11 19:47:13.050772: Epoch 79 
2025-11-11 19:47:13.050992: Current learning rate: 7e-05 
2025-11-11 19:49:28.100705: train_loss -0.4516 
2025-11-11 19:49:28.101232: val_loss -0.2884 
2025-11-11 19:49:28.101447: Pseudo dice [0.7232] 
2025-11-11 19:49:28.101718: Epoch time: 135.05 s 
2025-11-11 19:49:29.533659:  
2025-11-11 19:49:29.534032: Epoch 80 
2025-11-11 19:49:29.534213: Current learning rate: 7e-05 
2025-11-11 19:51:37.123761: train_loss -0.4589 
2025-11-11 19:51:37.124119: val_loss -0.3579 
2025-11-11 19:51:37.124294: Pseudo dice [0.7497] 
2025-11-11 19:51:37.124431: Epoch time: 127.59 s 
2025-11-11 19:51:38.524739:  
2025-11-11 19:51:38.525093: Epoch 81 
2025-11-11 19:51:38.525266: Current learning rate: 7e-05 
2025-11-11 19:53:51.675287: train_loss -0.4605 
2025-11-11 19:53:51.675673: val_loss -0.3565 
2025-11-11 19:53:51.675822: Pseudo dice [0.7602] 
2025-11-11 19:53:51.675977: Epoch time: 133.15 s 
2025-11-11 19:53:53.167345:  
2025-11-11 19:53:53.167712: Epoch 82 
2025-11-11 19:53:53.167849: Current learning rate: 6e-05 
2025-11-11 19:56:01.570434: train_loss -0.4617 
2025-11-11 19:56:01.570807: val_loss -0.3875 
2025-11-11 19:56:01.570927: Pseudo dice [0.7855] 
2025-11-11 19:56:01.571042: Epoch time: 128.41 s 
2025-11-11 19:56:02.917979:  
2025-11-11 19:56:02.918351: Epoch 83 
2025-11-11 19:56:02.918512: Current learning rate: 6e-05 
2025-11-11 19:58:10.488569: train_loss -0.4939 
2025-11-11 19:58:10.488963: val_loss -0.3899 
2025-11-11 19:58:10.489194: Pseudo dice [0.7674] 
2025-11-11 19:58:10.489320: Epoch time: 127.57 s 
2025-11-11 19:58:11.898978:  
2025-11-11 19:58:11.899344: Epoch 84 
2025-11-11 19:58:11.899509: Current learning rate: 6e-05 
2025-11-11 20:00:19.787070: train_loss -0.4869 
2025-11-11 20:00:19.787374: val_loss -0.3977 
2025-11-11 20:00:19.787512: Pseudo dice [0.7763] 
2025-11-11 20:00:19.787626: Epoch time: 127.89 s 
2025-11-11 20:00:21.156782:  
2025-11-11 20:00:21.157121: Epoch 85 
2025-11-11 20:00:21.157279: Current learning rate: 5e-05 
2025-11-11 20:02:26.005293: train_loss -0.5006 
2025-11-11 20:02:26.005643: val_loss -0.266 
2025-11-11 20:02:26.005752: Pseudo dice [0.7261] 
2025-11-11 20:02:26.005872: Epoch time: 124.85 s 
2025-11-11 20:02:27.468144:  
2025-11-11 20:02:27.468542: Epoch 86 
2025-11-11 20:02:27.468814: Current learning rate: 5e-05 
2025-11-11 20:04:37.243205: train_loss -0.4902 
2025-11-11 20:04:37.243673: val_loss -0.272 
2025-11-11 20:04:37.243780: Pseudo dice [0.7266] 
2025-11-11 20:04:37.243898: Epoch time: 129.78 s 
2025-11-11 20:04:38.652746:  
2025-11-11 20:04:38.653074: Epoch 87 
2025-11-11 20:04:38.653272: Current learning rate: 5e-05 
2025-11-11 20:06:46.929486: train_loss -0.4868 
2025-11-11 20:06:46.929899: val_loss -0.3551 
2025-11-11 20:06:46.930010: Pseudo dice [0.7556] 
2025-11-11 20:06:46.930148: Epoch time: 128.28 s 
2025-11-11 20:06:48.333389:  
2025-11-11 20:06:48.333693: Epoch 88 
2025-11-11 20:06:48.333910: Current learning rate: 4e-05 
2025-11-11 20:09:00.649912: train_loss -0.5295 
2025-11-11 20:09:00.650463: val_loss -0.388 
2025-11-11 20:09:00.650599: Pseudo dice [0.7661] 
2025-11-11 20:09:00.650712: Epoch time: 132.32 s 
2025-11-11 20:09:02.086999:  
2025-11-11 20:09:02.087393: Epoch 89 
2025-11-11 20:09:02.087537: Current learning rate: 4e-05 
2025-11-11 20:11:28.237867: train_loss -0.4911 
2025-11-11 20:11:28.238218: val_loss -0.3856 
2025-11-11 20:11:28.238327: Pseudo dice [0.7721] 
2025-11-11 20:11:28.238442: Epoch time: 146.15 s 
2025-11-11 20:11:29.786590:  
2025-11-11 20:11:29.786904: Epoch 90 
2025-11-11 20:11:29.787138: Current learning rate: 4e-05 
2025-11-11 20:13:41.072840: train_loss -0.4967 
2025-11-11 20:13:41.073269: val_loss -0.3568 
2025-11-11 20:13:41.073747: Pseudo dice [0.7568] 
2025-11-11 20:13:41.074005: Epoch time: 131.29 s 
2025-11-11 20:13:42.643629:  
2025-11-11 20:13:42.644074: Epoch 91 
2025-11-11 20:13:42.644221: Current learning rate: 3e-05 
2025-11-11 20:15:58.124631: train_loss -0.5026 
2025-11-11 20:15:58.125130: val_loss -0.4001 
2025-11-11 20:15:58.125281: Pseudo dice [0.7758] 
2025-11-11 20:15:58.125441: Epoch time: 135.48 s 
2025-11-11 20:15:58.125565: Yayy! New best EMA pseudo Dice: 0.7553 
2025-11-11 20:16:02.399197:  
2025-11-11 20:16:02.399592: Epoch 92 
2025-11-11 20:16:02.399733: Current learning rate: 3e-05 
2025-11-11 20:18:15.460343: train_loss -0.496 
2025-11-11 20:18:15.460846: val_loss -0.391 
2025-11-11 20:18:15.460959: Pseudo dice [0.7714] 
2025-11-11 20:18:15.461076: Epoch time: 133.06 s 
2025-11-11 20:18:15.461166: Yayy! New best EMA pseudo Dice: 0.7569 
2025-11-11 20:18:19.764372:  
2025-11-11 20:18:19.764737: Epoch 93 
2025-11-11 20:18:19.764881: Current learning rate: 3e-05 
2025-11-11 20:20:34.439087: train_loss -0.5047 
2025-11-11 20:20:34.439466: val_loss -0.297 
2025-11-11 20:20:34.439584: Pseudo dice [0.737] 
2025-11-11 20:20:34.439700: Epoch time: 134.68 s 
2025-11-11 20:20:35.818303:  
2025-11-11 20:20:35.818665: Epoch 94 
2025-11-11 20:20:35.818815: Current learning rate: 2e-05 
2025-11-11 20:22:43.971696: train_loss -0.5234 
2025-11-11 20:22:43.972030: val_loss -0.3668 
2025-11-11 20:22:43.972152: Pseudo dice [0.771] 
2025-11-11 20:22:43.972283: Epoch time: 128.16 s 
2025-11-11 20:22:45.903737:  
2025-11-11 20:22:45.904069: Epoch 95 
2025-11-11 20:22:45.904247: Current learning rate: 2e-05 
2025-11-11 20:25:11.872916: train_loss -0.5364 
2025-11-11 20:25:11.873350: val_loss -0.4155 
2025-11-11 20:25:11.873479: Pseudo dice [0.7778] 
2025-11-11 20:25:11.873609: Epoch time: 145.97 s 
2025-11-11 20:25:11.873711: Yayy! New best EMA pseudo Dice: 0.7586 
2025-11-11 20:25:20.004801:  
2025-11-11 20:25:20.005197: Epoch 96 
2025-11-11 20:25:20.005333: Current learning rate: 2e-05 
2025-11-11 20:27:34.612259: train_loss -0.5264 
2025-11-11 20:27:34.612617: val_loss -0.3602 
2025-11-11 20:27:34.612749: Pseudo dice [0.7708] 
2025-11-11 20:27:34.612925: Epoch time: 134.61 s 
2025-11-11 20:27:34.613040: Yayy! New best EMA pseudo Dice: 0.7599 
2025-11-11 20:27:38.586838:  
2025-11-11 20:27:38.587170: Epoch 97 
2025-11-11 20:27:38.587345: Current learning rate: 1e-05 
2025-11-11 20:29:49.389617: train_loss -0.5428 
2025-11-11 20:29:49.390061: val_loss -0.4319 
2025-11-11 20:29:49.390189: Pseudo dice [0.7853] 
2025-11-11 20:29:49.390319: Epoch time: 130.81 s 
2025-11-11 20:29:49.390410: Yayy! New best EMA pseudo Dice: 0.7624 
2025-11-11 20:29:53.029627:  
2025-11-11 20:29:53.029962: Epoch 98 
2025-11-11 20:29:53.030100: Current learning rate: 1e-05 
2025-11-11 20:32:10.596759: train_loss -0.5014 
2025-11-11 20:32:10.597184: val_loss -0.4087 
2025-11-11 20:32:10.597339: Pseudo dice [0.7737] 
2025-11-11 20:32:10.597540: Epoch time: 137.57 s 
2025-11-11 20:32:10.597636: Yayy! New best EMA pseudo Dice: 0.7635 
2025-11-11 20:32:14.746262:  
2025-11-11 20:32:14.746650: Epoch 99 
2025-11-11 20:32:14.746810: Current learning rate: 0.0 
2025-11-11 20:34:20.866930: train_loss -0.539 
2025-11-11 20:34:20.867347: val_loss -0.4 
2025-11-11 20:34:20.867464: Pseudo dice [0.7773] 
2025-11-11 20:34:20.867582: Epoch time: 126.12 s 
2025-11-11 20:34:20.867677: Yayy! New best EMA pseudo Dice: 0.7649 
2025-11-11 20:34:25.783821: Training done. 
2025-11-11 20:34:25.812213: Using splits from existing split file: /data/CXY/g/szy/data/nnUNet_preprocessed/Dataset502_DGAGA/splits_final.json 
2025-11-11 20:34:25.812769: The split file contains 5 splits. 
2025-11-11 20:34:25.812914: Desired fold for training: 2 
2025-11-11 20:34:25.813045: This split has 63 training and 16 validation cases. 
2025-11-11 20:34:25.813322: predicting 031368-20x-roi3 
2025-11-11 20:34:27.061276: 031368-20x-roi3, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:36:39.860815: predicting 032112-20x-roi1 
2025-11-11 20:36:41.127479: 032112-20x-roi1, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:38:07.600798: predicting 032112-20x-roi5 
2025-11-11 20:38:09.011860: 032112-20x-roi5, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:39:35.154895: predicting 032112c-20x-roi5 
2025-11-11 20:39:36.273612: 032112c-20x-roi5, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:41:00.169066: predicting 032236C-20x-roi3 
2025-11-11 20:41:01.388391: 032236C-20x-roi3, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:42:25.523092: predicting 032979-20x-roi6 
2025-11-11 20:42:26.931020: 032979-20x-roi6, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:43:30.248977: predicting 033942-20x-roi1 
2025-11-11 20:43:31.591875: 033942-20x-roi1, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:44:25.065151: predicting 033942C-20x-roi5 
2025-11-11 20:44:26.244354: 033942C-20x-roi5, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:45:19.744567: predicting 034250-20x-roi2 
2025-11-11 20:45:20.843083: 034250-20x-roi2, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:46:14.418330: predicting 040186-20x-roi3 
2025-11-11 20:46:15.491894: 040186-20x-roi3, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:47:08.872796: predicting 040483-20x-roi3 
2025-11-11 20:47:09.988288: 040483-20x-roi3, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:48:02.893183: predicting 041602_2-20x-roi5 
2025-11-11 20:48:04.200768: 041602_2-20x-roi5, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:49:27.821415: predicting 042145-20x-roi6 
2025-11-11 20:49:29.073048: 042145-20x-roi6, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:50:50.888933: predicting 042145_2-20x-roi9 
2025-11-11 20:50:52.101728: 042145_2-20x-roi9, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:51:45.651963: predicting 050323_2-20x-roi5 
2025-11-11 20:51:46.831129: 050323_2-20x-roi5, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:52:40.064231: predicting 050624-20x-roi1 
2025-11-11 20:52:41.158109: 050624-20x-roi1, shape torch.Size([1, 1280, 1024, 60]), rank 0 
2025-11-11 20:53:44.419093: Validation complete 
2025-11-11 20:53:44.419259: Mean Validation Dice:  0.7356298766818528 
