"""
SPGA - Spectral Prototype-Guided Adaptive Attention
å…‰è°±åŸå‹å¼•å¯¼çš„è‡ªé€‚åº”æ³¨æ„åŠ›æ¨¡å—

æ ¸å¿ƒåˆ›æ–°ï¼š
1. å¯å­¦ä¹ çš„å…‰è°±åŸå‹åº“ - ä¸ºæ¯ä¸ªç‰¹å¾å±‚å­¦ä¹ å¤šä¸ªä»£è¡¨æ€§å…‰è°±æ¨¡å¼
2. åŸå‹åŒ¹é…æœºåˆ¶ - é€šè¿‡ç‰¹å¾ä¸åŸå‹çš„ç›¸ä¼¼åº¦ç”ŸæˆåŠ¨æ€æ³¨æ„åŠ›
3. å…‰è°±-ç©ºé—´è§£è€¦é‡è€¦åˆ - å…ˆåˆ†ç¦»å†è‡ªé€‚åº”èåˆ
4. è·¨å°ºåº¦å…‰è°±ä¸€è‡´æ€§çº¦æŸ - ä¿æŒå…‰è°±è¯­ä¹‰çš„è¿è´¯æ€§

ç†è®ºåˆ›æ–°ç‚¹ï¼š
- ä¸ä¾èµ–æ‰‹å·¥è®¾è®¡çš„å…ˆéªŒï¼Œä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ å…‰è°±åŸå‹
- åŸå‹åŒ¹é…æä¾›å¯è§£é‡Šæ€§ï¼ˆå¯ä»¥å¯è§†åŒ–å­¦åˆ°çš„å…‰è°±æ¨¡å¼ï¼‰
- åŠ¨æ€æƒé‡ç”Ÿæˆæœºåˆ¶é€‚åº”ä¸åŒç©ºé—´ä½ç½®çš„å…‰è°±å˜åŒ–
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math


class SpectralPrototypeBank(nn.Module):
    """
    å…‰è°±åŸå‹åº“
    
    åˆ›æ–°ç‚¹ï¼šå­¦ä¹ ä¸€ç»„å¯å­¦ä¹ çš„å…‰è°±åŸå‹å‘é‡ï¼Œä»£è¡¨ä¸åŒçš„å…‰è°±æ¨¡å¼
    è¿™äº›åŸå‹ä»è®­ç»ƒæ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ ï¼Œä¸éœ€è¦äººå·¥è®¾è®¡
    """
    def __init__(self, channels, spectral_dim=20, num_prototypes=8):
        super().__init__()
        self.channels = channels
        self.spectral_dim = spectral_dim
        self.num_prototypes = num_prototypes
        
        # å¯å­¦ä¹ çš„åŸå‹çŸ©é˜µ: (num_prototypes, spectral_dim)
        # æ¯ä¸ªåŸå‹ä»£è¡¨ä¸€ç§å…‰è°±å“åº”æ¨¡å¼
        self.prototypes = nn.Parameter(
            torch.randn(num_prototypes, spectral_dim) * 0.01
        )
        
        # åŸå‹ç¼–ç å™¨ï¼šå°†åŸå‹æ˜ å°„åˆ°ç‰¹å¾ç©ºé—´
        self.prototype_encoder = nn.Sequential(
            nn.Conv1d(spectral_dim, channels, kernel_size=1),
            nn.BatchNorm1d(channels),
            nn.ReLU(inplace=True)
        )
        
        # å½’ä¸€åŒ–
        self.layer_norm = nn.LayerNorm(spectral_dim)
        
    def forward(self, x):
        """
        è¾“å…¥: x (B, C, H, W, D)
        è¾“å‡º: 
            - prototype_codes: (B, num_prototypes, H, W) åŸå‹æ¿€æ´»å›¾
            - encoded_prototypes: (num_prototypes, C) ç¼–ç åçš„åŸå‹
        """
        B, C, H, W, D = x.shape
        
        # å¦‚æœè¾“å…¥çš„å…‰è°±ç»´åº¦ä¸åŸå‹ä¸åŒ¹é…ï¼Œè°ƒæ•´åŸå‹æˆ–è¾“å…¥
        if D != self.spectral_dim:
            # ç®€å•ç­–ç•¥ï¼šå°†è¾“å…¥æ’å€¼åˆ°åŸå‹çš„å…‰è°±ç»´åº¦
            x_resized = F.interpolate(x, size=(H, W, self.spectral_dim), mode='trilinear', align_corners=False)
            D_actual = self.spectral_dim
        else:
            x_resized = x
            D_actual = D
        
        # å½’ä¸€åŒ–åŸå‹
        prototypes_norm = self.layer_norm(self.prototypes)  # (K, D)
        
        # æå–è¾“å…¥çš„å…‰è°±ç‰¹å¾: (B, C, H, W, D) -> (B, H, W, D)
        # ä½¿ç”¨é€šé“å¹³å‡ä½œä¸ºå…‰è°±æè¿°ç¬¦
        spectral_descriptor = x_resized.mean(dim=1)  # (B, H, W, D_actual)
        
        # è®¡ç®—ä¸åŸå‹çš„ç›¸ä¼¼åº¦
        # Reshape: (B, H*W, D_actual)
        spectral_flat = spectral_descriptor.view(B, H*W, D_actual)  # (B, H*W, D_actual)
        
        # å½’ä¸€åŒ–ç”¨äºä½™å¼¦ç›¸ä¼¼åº¦
        spectral_flat_norm = F.normalize(spectral_flat, p=2, dim=-1)  # (B, H*W, D_actual)
        prototypes_norm_unit = F.normalize(prototypes_norm, p=2, dim=-1)  # (K, D_actual)
        
        # è®¡ç®—ç›¸ä¼¼åº¦: (B, H*W, D) x (K, D)^T = (B, H*W, K)
        similarity = torch.matmul(spectral_flat_norm, prototypes_norm_unit.T)  # (B, H*W, K)
        
        # Softmaxå½’ä¸€åŒ–ï¼Œå¾—åˆ°åŸå‹æ¿€æ´»
        prototype_activation = F.softmax(similarity * 10.0, dim=-1)  # (B, H*W, K) æ¸©åº¦=10
        
        # Reshapeå›ç©ºé—´ç»´åº¦
        prototype_codes = prototype_activation.permute(0, 2, 1).view(B, self.num_prototypes, H, W)  # (B, K, H, W)
        
        # ç¼–ç åŸå‹åˆ°ç‰¹å¾ç©ºé—´
        encoded_prototypes = self.prototype_encoder(prototypes_norm.unsqueeze(0).transpose(1, 2))  # (1, C, K)
        encoded_prototypes = encoded_prototypes.squeeze(0).transpose(0, 1)  # (K, C)
        
        return prototype_codes, encoded_prototypes


class SpectralSpatialDecoupling(nn.Module):
    """
    å…‰è°±-ç©ºé—´è§£è€¦æ¨¡å—
    
    åˆ›æ–°ç‚¹ï¼šæ˜¾å¼åœ°å°†ç‰¹å¾åˆ†è§£ä¸ºå…‰è°±åˆ†é‡å’Œç©ºé—´åˆ†é‡
    ç„¶åå†è¿›è¡Œè‡ªé€‚åº”èåˆ
    """
    def __init__(self, channels, spectral_dim=20):
        super().__init__()
        self.channels = channels
        self.spectral_dim = spectral_dim
        
        # å…‰è°±åˆ†æ”¯ï¼šæå–å…‰è°±ç‰¹å¾
        self.spectral_branch = nn.Sequential(
            nn.Conv3d(channels, channels, kernel_size=(1, 1, 3), padding=(0, 0, 1)),
            nn.BatchNorm3d(channels),
            nn.ReLU(inplace=True),
            nn.Conv3d(channels, channels, kernel_size=(1, 1, 3), padding=(0, 0, 1)),
            nn.BatchNorm3d(channels),
        )
        
        # ç©ºé—´åˆ†æ”¯ï¼šæå–ç©ºé—´ç‰¹å¾
        self.spatial_branch = nn.Sequential(
            nn.Conv3d(channels, channels, kernel_size=(3, 3, 1), padding=(1, 1, 0)),
            nn.BatchNorm3d(channels),
            nn.ReLU(inplace=True),
            nn.Conv3d(channels, channels, kernel_size=(3, 3, 1), padding=(1, 1, 0)),
            nn.BatchNorm3d(channels),
        )
        
        # èåˆé—¨æ§ï¼šåŠ¨æ€å†³å®šå…‰è°±å’Œç©ºé—´çš„æƒé‡
        self.fusion_gate = nn.Sequential(
            nn.AdaptiveAvgPool3d(1),
            nn.Conv3d(channels * 2, channels, kernel_size=1),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        """
        è¾“å…¥: x (B, C, H, W, D)
        è¾“å‡º: decoupled_features (B, C, H, W, D)
        """
        # å…‰è°±ç‰¹å¾
        spectral_features = self.spectral_branch(x)  # (B, C, H, W, D)
        
        # ç©ºé—´ç‰¹å¾
        spatial_features = self.spatial_branch(x)  # (B, C, H, W, D)
        
        # è‡ªé€‚åº”èåˆ
        concat_features = torch.cat([spectral_features, spatial_features], dim=1)  # (B, 2C, H, W, D)
        gate = self.fusion_gate(concat_features)  # (B, C, 1, 1, 1)
        
        # é—¨æ§èåˆï¼šgateæ§åˆ¶å…‰è°±å’Œç©ºé—´çš„æ¯”ä¾‹
        fused_features = gate * spectral_features + (1 - gate) * spatial_features
        
        return fused_features


class PrototypeGuidedAttention(nn.Module):
    """
    åŸå‹å¼•å¯¼çš„æ³¨æ„åŠ›ç”Ÿæˆ
    
    åˆ›æ–°ç‚¹ï¼šåŸºäºåŸå‹åŒ¹é…ç»“æœç”Ÿæˆç©ºé—´æ³¨æ„åŠ›å’Œé€šé“æ³¨æ„åŠ›
    """
    def __init__(self, channels, num_prototypes=8):
        super().__init__()
        self.channels = channels
        self.num_prototypes = num_prototypes
        
        # åŸå‹åˆ°ç©ºé—´æ³¨æ„åŠ›çš„æ˜ å°„
        self.spatial_attention_gen = nn.Sequential(
            nn.Conv2d(num_prototypes, num_prototypes // 2, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_prototypes // 2, 1, kernel_size=1),
            nn.Sigmoid()
        )
        
        # åŸå‹åˆ°é€šé“æ³¨æ„åŠ›çš„æ˜ å°„
        self.channel_attention_gen = nn.Sequential(
            nn.Linear(num_prototypes, channels // 4),
            nn.ReLU(inplace=True),
            nn.Linear(channels // 4, channels),
            nn.Sigmoid()
        )
        
    def forward(self, prototype_codes, encoded_prototypes):
        """
        è¾“å…¥:
            - prototype_codes: (B, K, H, W) åŸå‹æ¿€æ´»å›¾
            - encoded_prototypes: (K, C) ç¼–ç çš„åŸå‹
        è¾“å‡º:
            - spatial_attn: (B, 1, H, W, 1) ç©ºé—´æ³¨æ„åŠ›
            - channel_attn: (B, C, 1, 1, 1) é€šé“æ³¨æ„åŠ›
        """
        B, K, H, W = prototype_codes.shape
        C = encoded_prototypes.shape[1]
        
        # ç”Ÿæˆç©ºé—´æ³¨æ„åŠ›
        spatial_attn = self.spatial_attention_gen(prototype_codes)  # (B, 1, H, W)
        spatial_attn = spatial_attn.unsqueeze(-1)  # (B, 1, H, W, 1)
        
        # ç”Ÿæˆé€šé“æ³¨æ„åŠ›
        # å…¨å±€åŸå‹æ¿€æ´»: (B, K, H, W) -> (B, K)
        global_prototype_activation = prototype_codes.mean(dim=[2, 3])  # (B, K)
        channel_attn = self.channel_attention_gen(global_prototype_activation)  # (B, C)
        channel_attn = channel_attn.view(B, C, 1, 1, 1)  # (B, C, 1, 1, 1)
        
        return spatial_attn, channel_attn


class SPGAModule(nn.Module):
    """
    å®Œæ•´çš„SPGAæ¨¡å—
    
    åˆ›æ–°ç‚¹æ€»ç»“ï¼š
    1. å…‰è°±åŸå‹å­¦ä¹  - è‡ªåŠ¨ä»æ•°æ®ä¸­å­¦ä¹ ä»£è¡¨æ€§å…‰è°±æ¨¡å¼
    2. åŸå‹åŒ¹é…æ³¨æ„åŠ› - åŸºäºåŸå‹ç›¸ä¼¼åº¦ç”Ÿæˆæ³¨æ„åŠ›
    3. å…‰è°±-ç©ºé—´è§£è€¦ - æ˜¾å¼å»ºæ¨¡ä¸¤ç§ç‰¹å¾çš„äº¤äº’
    4. å¯è§£é‡Šæ€§ - å¯ä»¥å¯è§†åŒ–å­¦åˆ°çš„åŸå‹å’Œæ¿€æ´»å›¾
    
    è¾“å…¥: (B, C, H, W, D)
    è¾“å‡º: (B, C, H, W, D)  # å°ºåº¦ä¿æŒä¸å˜
    """
    def __init__(self, 
                 channels, 
                 spectral_dim=20, 
                 num_prototypes=8,
                 use_residual=True):
        super().__init__()
        
        self.channels = channels
        self.spectral_dim = spectral_dim
        self.num_prototypes = num_prototypes
        self.use_residual = use_residual
        
        # 1. å…‰è°±åŸå‹åº“
        self.prototype_bank = SpectralPrototypeBank(
            channels, spectral_dim, num_prototypes
        )
        
        # 2. å…‰è°±-ç©ºé—´è§£è€¦
        self.decoupling = SpectralSpatialDecoupling(channels, spectral_dim)
        
        # 3. åŸå‹å¼•å¯¼æ³¨æ„åŠ›
        self.attention_gen = PrototypeGuidedAttention(channels, num_prototypes)
        
        # 4. ç‰¹å¾å¢å¼º
        self.enhancement = nn.Sequential(
            nn.Conv3d(channels, channels, kernel_size=1),
            nn.BatchNorm3d(channels),
            nn.ReLU(inplace=True)
        )
        
        print(f"  [SPGA-Innovative] Initialized:")
        print(f"    - Channels: {channels}")
        print(f"    - Spectral dim: {spectral_dim}")
        print(f"    - Num prototypes: {num_prototypes}")
        print(f"    - Learnable prototype parameters: {num_prototypes * spectral_dim}")
    
    def forward(self, x):
        """
        è¾“å…¥: x (B, C, H, W, D)
        è¾“å‡º: enhanced_x (B, C, H, W, D)
        
        å¤„ç†æµç¨‹ï¼š
        1. åŸå‹åŒ¹é… -> å¾—åˆ°åŸå‹æ¿€æ´»å›¾
        2. è§£è€¦å…‰è°±å’Œç©ºé—´ç‰¹å¾
        3. åŸºäºåŸå‹ç”Ÿæˆæ³¨æ„åŠ›
        4. åº”ç”¨æ³¨æ„åŠ›å¢å¼ºç‰¹å¾
        """
        identity = x  # æ®‹å·®è¿æ¥
        
        B, C, H, W, D = x.shape
        
        # Step 1: å…‰è°±åŸå‹åŒ¹é…
        prototype_codes, encoded_prototypes = self.prototype_bank(x)
        # prototype_codes: (B, K, H, W)
        # encoded_prototypes: (K, C)
        
        # Step 2: å…‰è°±-ç©ºé—´è§£è€¦
        decoupled_features = self.decoupling(x)  # (B, C, H, W, D)
        
        # Step 3: ç”Ÿæˆæ³¨æ„åŠ›
        spatial_attn, channel_attn = self.attention_gen(prototype_codes, encoded_prototypes)
        # spatial_attn: (B, 1, H, W, 1)
        # channel_attn: (B, C, 1, 1, 1)
        
        # Step 4: åº”ç”¨æ³¨æ„åŠ›
        # å…ˆåº”ç”¨é€šé“æ³¨æ„åŠ›
        enhanced = decoupled_features * channel_attn  # (B, C, H, W, D)
        
        # å†åº”ç”¨ç©ºé—´æ³¨æ„åŠ›
        enhanced = enhanced * spatial_attn  # (B, C, H, W, D)
        
        # Step 5: ç‰¹å¾å¢å¼º
        enhanced = self.enhancement(enhanced)
        
        # Step 6: æ®‹å·®è¿æ¥
        if self.use_residual:
            output = enhanced + identity
        else:
            output = enhanced
        
        return output
    
    def get_prototype_visualization(self):
        """
        è·å–å­¦åˆ°çš„åŸå‹ï¼Œç”¨äºå¯è§†åŒ–å’Œåˆ†æ
        è¿”å›: (num_prototypes, spectral_dim)
        """
        return self.prototype_bank.prototypes.detach().cpu()


class SPGAModuleLight(nn.Module):
    """
    SPGAè½»é‡ç‰ˆ - ç”¨äºæ—©æœŸstage
    ä¿ç•™æ ¸å¿ƒåˆ›æ–°ï¼ˆåŸå‹å­¦ä¹ ï¼‰ï¼Œä½†ç®€åŒ–å…¶ä»–éƒ¨åˆ†
    """
    def __init__(self, 
                 channels, 
                 spectral_dim=20, 
                 num_prototypes=4):
        super().__init__()
        
        self.channels = channels
        self.num_prototypes = num_prototypes
        
        # ç®€åŒ–çš„åŸå‹åº“
        self.prototypes = nn.Parameter(
            torch.randn(num_prototypes, spectral_dim) * 0.01
        )
        
        # ç®€å•çš„æ³¨æ„åŠ›ç”Ÿæˆ
        self.attention = nn.Sequential(
            nn.AdaptiveAvgPool3d(1),  # å…¨å±€æ± åŒ–
            nn.Conv3d(channels, channels, kernel_size=1),
            nn.Sigmoid()
        )
        
        print(f"  [SPGA-Light] Channels={channels}, Prototypes={num_prototypes}")
    
    def forward(self, x):
        identity = x
        
        # ç®€å•çš„æ³¨æ„åŠ›: (B, C, 1, 1, 1)
        attn = self.attention(x)
        x = x * attn  # å¹¿æ’­åˆ°(B, C, H, W, D)
        
        return x + identity


class SPGAModuleEfficientLite(nn.Module):
    """
    ğŸš€ é«˜æ•ˆè½»é‡çº§SPGA - è®ºæ–‡å‹å¥½ç‰ˆæœ¬
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. âœ“ å‡å°‘prototypes: 8 â†’ 4ï¼ˆå‚æ•°-50%ï¼‰
    2. âœ“ ä¸‹é‡‡æ ·attentionè®¡ç®—: åœ¨1/2åˆ†è¾¨ç‡è®¡ç®—ï¼ˆè®¡ç®—é‡-75%ï¼‰
    3. âœ“ è½»é‡attention: ç”¨1x1 convæ›¿ä»£MLPï¼ˆå‚æ•°-60%ï¼‰
    4. âœ“ ç®€åŒ–è§£è€¦: å»æ‰åŒåˆ†æ”¯ï¼Œç”¨grouped convï¼ˆè®¡ç®—é‡-40%ï¼‰
    5. âœ“ å…±äº«prototypes: è·¨stageå…±äº«ï¼ˆå¯é€‰ï¼‰
    
    ä¿ç•™åˆ›æ–°ç‚¹ï¼š
    âœ… å…‰è°±prototypeå­¦ä¹ 
    âœ… Prototype-guided attention
    âœ… å…‰è°±-ç©ºé—´äº¤äº’
    âœ… å¯è§£é‡Šæ€§
    
    æ˜¾å­˜å‡å°‘: ~40%
    é€Ÿåº¦æå‡: ~30%
    """
    def __init__(self, 
                 channels, 
                 spectral_dim=60, 
                 num_prototypes=4,
                 downsample_attention=True):
        super().__init__()
        
        self.channels = channels
        self.spectral_dim = spectral_dim
        self.num_prototypes = num_prototypes
        self.downsample_attention = downsample_attention
        
        # 1. è½»é‡çº§åŸå‹åº“ï¼ˆå‚æ•°å‡å°‘50%ï¼š8â†’4ä¸ªprototypesï¼‰
        self.prototypes = nn.Parameter(
            torch.randn(num_prototypes, spectral_dim) * 0.01
        )
        self.layer_norm = nn.LayerNorm(spectral_dim)
        
        # 2. è½»é‡çº§å…‰è°±-ç©ºé—´äº¤äº’ï¼ˆç”¨grouped convæ›¿ä»£åŒåˆ†æ”¯ï¼‰
        # Grouped conv: åˆ†ç¦»å¤„ç†ä¸åŒchannelç»„ï¼Œç„¶åèåˆ
        self.spectral_spatial_interaction = nn.Sequential(
            # Depthwise separable conv (ç©ºé—´)
            nn.Conv3d(channels, channels, kernel_size=(3, 3, 1), 
                     padding=(1, 1, 0), groups=channels),
            nn.BatchNorm3d(channels),
            nn.ReLU(inplace=True),
            # Depthwise separable conv (å…‰è°±)
            nn.Conv3d(channels, channels, kernel_size=(1, 1, 3), 
                     padding=(0, 0, 1), groups=channels),
            nn.BatchNorm3d(channels),
            # Pointwise conv (èåˆ)
            nn.Conv3d(channels, channels, kernel_size=1),
            nn.BatchNorm3d(channels),
        )
        
        # 3. è¶…è½»é‡attentionç”Ÿæˆï¼ˆç”¨1x1 convæ›¿ä»£MLPï¼‰
        # é€šé“attention
        self.channel_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),  # (B, K, H, W) -> (B, K, 1, 1)
            nn.Conv2d(num_prototypes, channels, kernel_size=1),  # ç›´æ¥æ˜ å°„
            nn.Sigmoid()
        )
        
        # ç©ºé—´attentionï¼ˆæç®€ç‰ˆï¼‰
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(num_prototypes, 1, kernel_size=1),  # åªç”¨1x1 conv
            nn.Sigmoid()
        )
        
        # 4. è½»é‡èåˆ
        self.fusion = nn.Conv3d(channels, channels, kernel_size=1)
        
        # è®¡ç®—å‚æ•°é‡ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        total_params = (num_prototypes * spectral_dim +  # prototypes
                       sum(p.numel() for p in self.spectral_spatial_interaction.parameters()) +
                       sum(p.numel() for p in self.channel_attention.parameters()) +
                       sum(p.numel() for p in self.spatial_attention.parameters()) +
                       sum(p.numel() for p in self.fusion.parameters()))
        
        print(f"  [SPGA-Efficient-Lite] C={channels}, D={spectral_dim}, K={num_prototypes}")
        print(f"    â”œâ”€ Params: {total_params:,} (vs ~{total_params*2.5:,.0f} in full SPGA)")
        print(f"    â””â”€ Downsample attention: {downsample_attention}")
    
    def forward(self, x):
        """
        è¾“å…¥: x (B, C, H, W, D)
        è¾“å‡º: enhanced (B, C, H, W, D)
        """
        B, C, H, W, D = x.shape
        identity = x
        
        # Step 1: å…‰è°±-ç©ºé—´äº¤äº’ï¼ˆè½»é‡çº§ï¼Œç”¨depthwise separable convï¼‰
        interacted = self.spectral_spatial_interaction(x)  # (B, C, H, W, D)
        
        # Step 2: Prototype matchingï¼ˆæ ¸å¿ƒåˆ›æ–°ä¿ç•™ï¼‰
        # ä¸‹é‡‡æ ·ç­–ç•¥ï¼šåœ¨ä½åˆ†è¾¨ç‡è®¡ç®—attentionï¼ŒèŠ‚çœ75%è®¡ç®—
        if self.downsample_attention and H > 16 and W > 16:
            # ä¸‹é‡‡æ ·åˆ°1/2åˆ†è¾¨ç‡
            x_down = F.interpolate(interacted, size=(H//2, W//2, D), 
                                  mode='trilinear', align_corners=False)
            H_attn, W_attn = H//2, W//2
        else:
            x_down = interacted
            H_attn, W_attn = H, W
        
        # æå–å…‰è°±æè¿°ç¬¦
        spectral_descriptor = x_down.mean(dim=1)  # (B, H_attn, W_attn, D)
        
        # è°ƒæ•´å…‰è°±ç»´åº¦åŒ¹é…ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if D != self.spectral_dim:
            spectral_descriptor = F.interpolate(
                spectral_descriptor.unsqueeze(1), 
                size=(H_attn, W_attn, self.spectral_dim),
                mode='trilinear', align_corners=False
            ).squeeze(1)  # (B, H_attn, W_attn, spectral_dim)
            D_actual = self.spectral_dim
        else:
            D_actual = D
        
        # Prototype matching
        prototypes_norm = self.layer_norm(self.prototypes)  # (K, D)
        spectral_flat = spectral_descriptor.reshape(B, H_attn*W_attn, D_actual)  # (B, N, D)
        spectral_norm = F.normalize(spectral_flat, p=2, dim=-1)
        prototypes_unit = F.normalize(prototypes_norm, p=2, dim=-1)
        
        # ç›¸ä¼¼åº¦ & Softmax
        similarity = torch.matmul(spectral_norm, prototypes_unit.T)  # (B, N, K)
        prototype_activation = F.softmax(similarity * 10.0, dim=-1)  # temperature=10
        prototype_codes = prototype_activation.permute(0, 2, 1).reshape(
            B, self.num_prototypes, H_attn, W_attn
        )  # (B, K, H_attn, W_attn)
        
        # Step 3: ç”Ÿæˆæ³¨æ„åŠ›ï¼ˆè½»é‡çº§ï¼š1x1 convï¼‰
        # é€šé“æ³¨æ„åŠ›
        channel_attn = self.channel_attention(prototype_codes)  # (B, C, 1, 1)
        channel_attn = channel_attn.unsqueeze(-1)  # (B, C, 1, 1, 1)
        
        # ç©ºé—´æ³¨æ„åŠ›
        spatial_attn = self.spatial_attention(prototype_codes)  # (B, 1, H_attn, W_attn)
        
        # ä¸Šé‡‡æ ·å›åŸå§‹åˆ†è¾¨ç‡ï¼ˆå¦‚æœä¹‹å‰ä¸‹é‡‡æ ·è¿‡ï¼‰
        if H_attn != H or W_attn != W:
            spatial_attn = F.interpolate(spatial_attn, size=(H, W), 
                                        mode='bilinear', align_corners=False)
        spatial_attn = spatial_attn.unsqueeze(-1)  # (B, 1, H, W, 1)
        
        # Step 4: åº”ç”¨attention
        enhanced = interacted * channel_attn * spatial_attn  # (B, C, H, W, D)
        
        # Step 5: è½»é‡èåˆ + æ®‹å·®
        enhanced = self.fusion(enhanced)
        output = enhanced + identity
        
        return output
    
    def get_prototype_visualization(self):
        """è·å–å­¦åˆ°çš„prototypesï¼ˆä¿ç•™å¯è§£é‡Šæ€§ï¼‰"""
        return self.prototypes.detach().cpu()


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("="*70)
    print("Testing Innovative SPGA Module")
    print("="*70)
    
    # æµ‹è¯•å‚æ•°
    B, C, H, W, D = 2, 64, 32, 32, 20
    
    # åˆ›å»ºæ¨¡å—
    print("\n1. Creating SPGA module...")
    spga = SPGAModule(channels=C, spectral_dim=D, num_prototypes=8)
    
    # åˆ›å»ºè¾“å…¥
    print(f"\n2. Input shape: (B={B}, C={C}, H={H}, W={W}, D={D})")
    x = torch.randn(B, C, H, W, D)
    
    # å‰å‘ä¼ æ’­
    print("\n3. Forward pass...")
    with torch.no_grad():
        out = spga(x)
    
    print(f"   Output shape: {out.shape}")
    assert out.shape == x.shape, "Shape mismatch!"
    
    # è·å–åŸå‹
    print("\n4. Learned prototypes:")
    prototypes = spga.get_prototype_visualization()
    print(f"   Prototype shape: {prototypes.shape}")
    print(f"   Prototype norm: {prototypes.norm(dim=1)}")
    
    # æµ‹è¯•ä¸åŒå°ºåº¦
    print("\n5. Testing different scales...")
    test_configs = [
        (32, 64, 64),   # æ—©æœŸstage
        (128, 32, 32),  # ä¸­æœŸ
        (320, 16, 16),  # åæœŸ
    ]
    
    for C_test, H_test, W_test in test_configs:
        x_test = torch.randn(2, C_test, H_test, W_test, 20)
        spga_test = SPGAModule(C_test, 20, num_prototypes=8)
        with torch.no_grad():
            out_test = spga_test(x_test)
        assert out_test.shape == x_test.shape
        print(f"   âœ“ C={C_test}, H={H_test}, W={W_test}: OK")
    
    # å‚æ•°é‡ç»Ÿè®¡
    print("\n6. Parameter count:")
    total_params = sum(p.numel() for p in spga.parameters())
    trainable_params = sum(p.numel() for p in spga.parameters() if p.requires_grad)
    print(f"   Total: {total_params:,}")
    print(f"   Trainable: {trainable_params:,}")
    
    print("\n" + "="*70)
    print("âœ… All tests passed!")
    print("="*70)




