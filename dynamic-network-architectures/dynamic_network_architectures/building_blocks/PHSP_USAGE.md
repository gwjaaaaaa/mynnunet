# PHSP (Prototype-Driven Hierarchical Spectral Prior) Usage Guide

## ğŸ“‹ æ¦‚è¿°

PHSPæ˜¯ä¸€ä¸ªåŸå‹é©±åŠ¨çš„å±‚çº§å…‰è°±å…ˆéªŒå­¦ä¹ æ¨¡å—ï¼Œç”¨äºæ›¿ä»£SSCAæ¨¡å—ã€‚

### **æ ¸å¿ƒåˆ›æ–°ï¼š**
1. **åŠ¨æ€å…‰è°±å…ˆéªŒ**ï¼šä»SPGAçš„è‡ªé€‚åº”åŸå‹ä¸­æå–ï¼ˆvs SSCAçš„é™æ€å…ˆéªŒï¼‰
2. **å±‚çº§ä¼ æ’­**ï¼šæœ‰åŸå‹stageæå–å±€éƒ¨å…ˆéªŒï¼Œæ— åŸå‹stageä»å…¨å±€ä¼ æ’­
3. **è½»é‡è®¾è®¡**ï¼š~48Kå‚æ•°ï¼Œ<10KBé¢å¤–æ˜¾å­˜
4. **ä¸SPGA/DSRæ·±åº¦é›†æˆ**ï¼šå……åˆ†åˆ©ç”¨å·²å­¦ä¹ çš„åŸå‹

### **å‚æ•°é‡å¯¹æ¯”ï¼š**
- SSCA: ~140Kå‚æ•°
- PHSP: ~48Kå‚æ•° âœ… **èŠ‚çœ66%ï¼**

---

## ğŸš€ å¦‚ä½•å¯ç”¨PHSP

### **Step 1: ä¿®æ”¹nnUNetTrainerHSI.pyé…ç½®**

åœ¨`__init__`æ–¹æ³•ä¸­ï¼š

```python
# ç¦ç”¨SSCAï¼Œå¯ç”¨PHSP
self.use_ssca = False    # âœ— ç¦ç”¨SSCA
self.use_phsp = True     # âœ“ å¯ç”¨PHSP
```

### **Step 2: ä¿®æ”¹build_network_architectureé…ç½®**

åœ¨`build_network_architecture`æ–¹æ³•ä¸­ï¼š

```python
# HSIå‚æ•°
use_ssca = False   # âœ— ç¦ç”¨SSCA
use_phsp = True    # âœ“ å¯ç”¨PHSP
```

### **Step 3: è®­ç»ƒ**

```bash
CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 502 3d_fullres 0 -tr nnUNetTrainerHSI
```

---

## ğŸ“Š PHSP Lossï¼ˆå¯é€‰ï¼‰

PHSPæä¾›ä¸¤ç§è¾…åŠ©æŸå¤±ï¼Œç”¨äºæå‡å…‰è°±å…ˆéªŒè´¨é‡ï¼š

### **1. Spectral Prior Smoothness Lossï¼ˆå¹³æ»‘æ€§çº¦æŸï¼‰**

**åŸç†ï¼š** ç›¸é‚»æ³¢æ®µçš„é‡è¦æ€§åº”è¯¥å¹³æ»‘è¿‡æ¸¡

**ä½¿ç”¨æ–¹æ³•ï¼š**

åœ¨trainerçš„`train_step`æ–¹æ³•ä¸­æ·»åŠ ï¼š

```python
def train_step(self, batch):
    data, target = batch
    
    # å‰å‘ä¼ æ’­
    pred = self.network(data)
    
    # ä¸»æŸå¤±
    seg_loss = self.loss(pred, target)
    
    # PHSPæŸå¤±ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if self.network.spectral_priors is not None:
        from dynamic_network_architectures.building_blocks.phsp_loss import SpectralPriorSmoothLoss
        
        smooth_loss_fn = SpectralPriorSmoothLoss(alpha=0.001, order=1)
        smooth_loss = smooth_loss_fn(self.network.spectral_priors)
        
        total_loss = seg_loss + smooth_loss
    else:
        total_loss = seg_loss
    
    return total_loss
```

**é…ç½®å‚æ•°ï¼š**
- `alpha`: æŸå¤±æƒé‡ï¼ˆé»˜è®¤0.001ï¼Œå¾ˆå°ï¼‰
- `order`: 
  - 1 = ä¸€é˜¶å·®åˆ†ï¼ˆç›¸é‚»æ³¢æ®µå·®å¼‚ï¼‰
  - 2 = äºŒé˜¶å·®åˆ†ï¼ˆæ›²ç‡çº¦æŸï¼‰

### **2. Spectral Prior Consistency Lossï¼ˆä¸€è‡´æ€§çº¦æŸï¼Œå¯é€‰ï¼‰**

**åŸç†ï¼š** ä¸åŒstageçš„å…‰è°±å…ˆéªŒåº”è¯¥ä¿æŒä¸€è‡´æ€§

**ä½¿ç”¨æ–¹æ³•ï¼š**

```python
from dynamic_network_architectures.building_blocks.phsp_loss import PHSPCompositeLoss

# åˆå§‹åŒ–å¤åˆæŸå¤±ï¼ˆåŒ…å«å¹³æ»‘æ€§+ä¸€è‡´æ€§ï¼‰
phsp_loss_fn = PHSPCompositeLoss(
    smooth_alpha=0.001,
    smooth_order=1,
    consistency_alpha=0.0005,
    use_consistency=True  # å¯ç”¨ä¸€è‡´æ€§æŸå¤±
)

# åœ¨train_stepä¸­ä½¿ç”¨
def train_step(self, batch):
    data, target = batch
    pred = self.network(data)
    seg_loss = self.loss(pred, target)
    
    if self.network.spectral_priors is not None:
        phsp_losses = phsp_loss_fn(self.network.spectral_priors)
        total_loss = seg_loss + phsp_losses['total']
    else:
        total_loss = seg_loss
    
    return total_loss
```

---

## ğŸ¯ PHSP vs SSCA å¯¹æ¯”

| ç‰¹æ€§ | SSCA | PHSP |
|------|------|------|
| **å…ˆéªŒæ¥æº** | ç¦»çº¿ç»Ÿè®¡ï¼ˆåŒé‡å¹³æ»‘ï¼‰ | **åœ¨çº¿ï¼Œä»SPGAåŸå‹æå–** |
| **åŠ¨æ€æ€§** | é™æ€ | **åŠ¨æ€ï¼Œéšè®­ç»ƒæ¼”åŒ–** |
| **ä¸SPGAé›†æˆ** | âŒ ç‹¬ç«‹ | **âœ… æ·±åº¦é›†æˆ** |
| **å‚æ•°é‡** | 140K | **48K (-66%)** |
| **æ˜¾å­˜å¼€é”€** | ä¸­ç­‰ | **æå°‘ (<10KB)** |
| **ç†è®ºåˆ›æ–°** | åŒé‡å¹³æ»‘å¯†åº¦ä¼°è®¡ | **åŸå‹é©±åŠ¨ + å±‚çº§ä¼ æ’­** |
| **è®ºæ–‡ä»·å€¼** | â­â­â­ | **â­â­â­â­â­** |

---

## ğŸ“ é…ç½®å‚æ•°è¯´æ˜

### **PHSPæ ¸å¿ƒå‚æ•°ï¼ˆbuild_phsp_moduleï¼‰ï¼š**

```python
phsp_module = build_phsp_module(
    channels_per_stage=[32, 64, 128, 256, 320, 320, 320],  # å„stageé€šé“æ•°
    spectral_dim=60,                                       # å…‰è°±ç»´åº¦
    num_prototypes=4,                                      # SPGAåŸå‹æ•°é‡
    spga_stages=[2, 3, 4]                                  # æœ‰SPGAçš„stage
)
```

### **PHSP Losså‚æ•°ï¼ˆåœ¨trainerä¸­é…ç½®ï¼‰ï¼š**

```python
# åœ¨nnUNetTrainerHSI.__init__ä¸­ï¼š
self.phsp_smooth_alpha = 0.001         # å¹³æ»‘æ€§æŸå¤±æƒé‡
self.phsp_smooth_order = 1             # 1=ä¸€é˜¶å·®åˆ†, 2=äºŒé˜¶å·®åˆ†
self.phsp_use_consistency = False      # æ˜¯å¦ä½¿ç”¨ä¸€è‡´æ€§æŸå¤±
self.phsp_consistency_alpha = 0.0005   # ä¸€è‡´æ€§æŸå¤±æƒé‡
```

---

## ğŸ”¬ å·¥ä½œåŸç†

### **Forward Passæµç¨‹ï¼š**

```
1. Encoder:
   x â†’ Stage 0 (no SPGA) â†’ skip[0]
   x â†’ Stage 1 (no SPGA) â†’ skip[1]
   x â†’ Stage 2 + SPGA â†’ skip[2] â† æå–åŸå‹P2
   x â†’ Stage 3 + SPGA â†’ skip[3] â† æå–åŸå‹P3
   x â†’ Stage 4 + SPGA â†’ skip[4] â† æå–åŸå‹P4
   x â†’ Stage 5 (no SPGA) â†’ skip[5]
   x â†’ Stage 6 (no SPGA) â†’ skip[6]

2. PHSP Module:
   â”œâ”€ ä»åŸå‹æå–å±€éƒ¨å…‰è°±å…ˆéªŒï¼š
   â”‚  Stage 2: P2 â†’ spectral_prior[2]
   â”‚  Stage 3: P3 â†’ spectral_prior[3]
   â”‚  Stage 4: P4 â†’ spectral_prior[4]
   â”‚
   â”œâ”€ è®¡ç®—å…¨å±€å…ˆéªŒï¼š
   â”‚  global_prior = mean(spectral_prior[2,3,4])
   â”‚
   â”œâ”€ ä¼ æ’­åˆ°æ— åŸå‹stageï¼š
   â”‚  Stage 0,1,5,6: global_prior â†’ è‡ªé€‚åº”ä¼ æ’­
   â”‚
   â””â”€ åº”ç”¨åˆ°è·³è·ƒè¿æ¥ï¼š
      refined_skip[i] = skip[i] * (1 + channel_weights * 0.3)

3. Decoder:
   refined_skips â†’ decoder â†’ output
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### **æ¨èé…ç½®ï¼ˆæ˜¾å­˜å……è¶³ï¼‰ï¼š**
```python
self.use_phsp = True
self.phsp_smooth_alpha = 0.001
self.phsp_smooth_order = 1
self.phsp_use_consistency = False  # ä¸€èˆ¬ä¸éœ€è¦
```

### **æç®€é…ç½®ï¼ˆä¸ä½¿ç”¨è¾…åŠ©lossï¼‰ï¼š**
```python
self.use_phsp = True
# ä¸æ·»åŠ PHSP lossï¼Œä»…ä½¿ç”¨åŠ¨æ€å…ˆéªŒ
```

### **å®Œæ•´é…ç½®ï¼ˆæœ€å¤§åŒ–æ€§èƒ½ï¼‰ï¼š**
```python
self.use_phsp = True
self.phsp_smooth_alpha = 0.001
self.phsp_smooth_order = 2  # äºŒé˜¶å·®åˆ†ï¼Œæ›´å¼ºçº¦æŸ
self.phsp_use_consistency = True
self.phsp_consistency_alpha = 0.0005
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### **é—®é¢˜1ï¼šImportError**
```
ImportError: cannot import name 'build_phsp_module'
```

**è§£å†³ï¼š** ç¡®ä¿æ–‡ä»¶å­˜åœ¨ä¸”è·¯å¾„æ­£ç¡®
```bash
ls /data/CXY/g/szy/dynamic-network-architectures/dynamic_network_architectures/building_blocks/phsp_module.py
```

### **é—®é¢˜2ï¼šPHSPå’ŒSSCAåŒæ—¶å¯ç”¨**
```
Warning: Both SSCA and PHSP are enabled!
```

**è§£å†³ï¼š** åªå¯ç”¨ä¸€ä¸ª
```python
self.use_ssca = False  # ç¦ç”¨SSCA
self.use_phsp = True   # å¯ç”¨PHSP
```

### **é—®é¢˜3ï¼šæ˜¾å­˜ä¸è¶³**
```
CUDA out of memory
```

**è§£å†³ï¼š** PHSPæœ¬èº«å¾ˆè½»é‡ï¼ˆ<10KBï¼‰ï¼Œå¦‚æœOOMï¼Œæ£€æŸ¥å…¶ä»–æ¨¡å—
```python
self.use_bear = False  # BEARæ˜¯OOMçš„ä¸»è¦åŸå› 
```

---

## ğŸ“š ç†è®ºèƒŒæ™¯

### **ä¸ºä»€ä¹ˆPHSPä¼˜äºSSCAï¼Ÿ**

1. **åŠ¨æ€ vs é™æ€**
   - SSCAï¼šç¦»çº¿è®¡ç®—ï¼Œå›ºå®šä¸å˜
   - PHSPï¼šåœ¨çº¿æå–ï¼Œéšè®­ç»ƒæ¼”åŒ– âœ…

2. **æ•°æ®é©±åŠ¨ vs ç»Ÿè®¡é©±åŠ¨**
   - SSCAï¼šåŸºäºå…¨å±€ç»Ÿè®¡
   - PHSPï¼šåŸºäºSPGAå­¦åˆ°çš„åŸå‹ï¼ˆæ›´ç²¾å‡†ï¼‰âœ…

3. **é›†æˆæ·±åº¦**
   - SSCAï¼šç‹¬ç«‹æ¨¡å—
   - PHSPï¼šæ·±åº¦é›†æˆSPGAï¼Œå½¢æˆé—­ç¯ âœ…

4. **ç†è®ºåˆ›æ–°**
   - SSCAï¼šåŒé‡å¹³æ»‘ï¼ˆç»Ÿè®¡å­¦ï¼‰
   - PHSPï¼šåŸå‹é©±åŠ¨ + å±‚çº§ä¼ æ’­ï¼ˆæ·±åº¦å­¦ä¹ +ç»Ÿè®¡å­¦ï¼‰âœ…

---

## ğŸ“– å¼•ç”¨

å¦‚æœä½¿ç”¨PHSPï¼Œå»ºè®®åœ¨è®ºæ–‡ä¸­è¿™æ ·æè¿°ï¼š

> *"We propose a Prototype-Driven Hierarchical Spectral Prior Learning (PHSP) module that dynamically extracts spectral priors from the learned prototypes in SPGA. Unlike traditional static spectral priors, PHSP leverages the adaptive nature of prototypes to generate data-driven priors that evolve during training. The hierarchical propagation mechanism ensures that all encoder stages, including those without explicit prototype learning, benefit from the spectral knowledge encoded in the prototypes."*

---

## ğŸ¯ æ€»ç»“

**ä½•æ—¶ä½¿ç”¨PHSPï¼š**
- âœ… å½“SSCAæ•ˆæœä¸ç†æƒ³æ—¶
- âœ… æƒ³è¦æ›´å¼ºçš„ç†è®ºåˆ›æ–°
- âœ… éœ€è¦è½»é‡åŒ–æ–¹æ¡ˆ
- âœ… æƒ³è¦ä¸SPGAæ·±åº¦é›†æˆ

**ä½•æ—¶ä½¿ç”¨SSCAï¼š**
- âœ… éœ€è¦å®Œå…¨ç‹¬ç«‹çš„å…ˆéªŒï¼ˆä¸ä¾èµ–SPGAï¼‰
- âœ… å¯¹åŒé‡å¹³æ»‘ç†è®ºæœ‰ç‰¹æ®Šéœ€æ±‚

**æ¨èï¼šä¼˜å…ˆå°è¯•PHSPï¼** ğŸš€

---

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œæ£€æŸ¥ï¼š
1. PHSPæ˜¯å¦æ­£ç¡®åˆå§‹åŒ–ï¼ˆæ£€æŸ¥æ—¥å¿—è¾“å‡ºï¼‰
2. SPGAæ˜¯å¦åœ¨stage [2,3,4]å¯ç”¨
3. å‰å‘ä¼ æ’­æ˜¯å¦æ­£ç¡®è°ƒç”¨PHSP
4. Lossæ˜¯å¦æ­£ç¡®è®¡ç®—ï¼ˆå¦‚æœä½¿ç”¨è¾…åŠ©lossï¼‰


